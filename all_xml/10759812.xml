<pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="editorial">
  <?properties open_access?>
  <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
    <restricted-by>pmc</restricted-by>
  </processing-meta>
  <front><journal-meta><journal-id journal-id-type="nlm-ta">Nat Sci Sleep</journal-id><journal-id journal-id-type="iso-abbrev">Nat Sci Sleep</journal-id><journal-id journal-id-type="publisher-id">nss</journal-id><journal-title-group><journal-title>Nature and Science of Sleep</journal-title></journal-title-group><issn pub-type="epub">1179-1608</issn><publisher><publisher-name>Dove</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">38170140</article-id><article-id pub-id-type="pmc">10759812</article-id><article-id pub-id-type="publisher-id">455765</article-id><article-id pub-id-type="doi">10.2147/NSS.S455765</article-id><article-categories><subj-group subj-group-type="heading"><subject>Editorial</subject></subj-group></article-categories><title-group><article-title>Balancing Innovation and Integrity: The Role of AI in Research and Scientific Writing</article-title><alt-title alt-title-type="running-authors">BaHammam</alt-title><alt-title alt-title-type="running-title">BaHammam</alt-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1706-6167</contrib-id><name><surname>BaHammam</surname><given-names>Ahmed S</given-names></name><xref rid="aff0001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff0002" ref-type="aff">
<sup>2</sup>
</xref><xref rid="aff0003" ref-type="aff">
<sup>3</sup>
</xref><xref rid="an0001" ref-type="corresp"/></contrib><aff id="aff0001">
<label>1</label>
<institution>Editor-in-Chief Nature and Science of Sleep</institution>
</aff><aff id="aff0002"><label>2</label><institution>Department of Medicine, University Sleep Disorders Center and Pulmonary Service, King Saud University</institution>, <addr-line>Riyadh</addr-line>, <country>Saudi Arabia</country></aff><aff id="aff0003"><label>3</label><institution>King Saud University Medical City</institution>, <addr-line>Riyadh</addr-line>, <country>Saudi Arabia</country></aff></contrib-group><author-notes><corresp id="an0001">Correspondence: Ahmed S BaHammam, <institution>Professor of Medicine, University Sleep Disorders Center, Department of Medicine, College of Medicine, King Saud University</institution>, <addr-line>Box 225503</addr-line>, <addr-line>Riyadh</addr-line>, <addr-line>11324</addr-line>, <country>Saudi Arabia</country>, <phone>Tel +966-11-467-9495</phone>, <fax>Fax +966-11-467-9179</fax>, Email ashammam2@gmail.com</corresp></author-notes><pub-date pub-type="epub"><day>29</day><month>12</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>15</volume><fpage>1153</fpage><lpage>1156</lpage><history><date date-type="received"><day>19</day><month>12</month><year>2023</year></date><date date-type="accepted"><day>21</day><month>12</month><year>2023</year></date></history><permissions><copyright-statement>© 2023 BaHammam.</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>BaHammam.</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/3.0/</ali:license_ref><license-p>This work is published and licensed by Dove Medical Press Limited. The full terms of this license are available at <ext-link ext-link-type="uri" xlink:href="https://www.dovepress.com/terms.php">https://www.dovepress.com/terms.php</ext-link> and incorporate the Creative Commons Attribution – Non Commercial (unported, v3.0) License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/3.0/">http://creativecommons.org/licenses/by-nc/3.0/</ext-link>). By accessing the work you hereby accept the Terms. Non-commercial uses of the work are permitted without any further permission from Dove Medical Press Limited, provided the work is properly attributed. For permission for commercial use of this work, please see paragraphs 4.2 and 5 of our Terms (<ext-link ext-link-type="uri" xlink:href="https://www.dovepress.com/terms.php">https://www.dovepress.com/terms.php</ext-link>).</license-p></license></permissions><counts><fig-count count="0"/><ref-count count="25"/><page-count count="4"/></counts></article-meta></front>
  <body>
    <p>
<disp-quote><p>Some people call this artificial intelligence, but the reality is this technology will enhance us. So instead of artificial intelligence, I think we’ll augment our intelligence.</p></disp-quote></p>
    <p>– Ginni Rometty</p>
    <p>In today’s scientific landscape, artificial intelligence (AI) is revolutionizing research methodologies and scientific writing, reshaping how we conduct and disseminate research. As AI’s presence grows, so do questions surrounding ethics, authenticity, and the integrity of scientific publications. The increasing use of AI tools, such as large language models (LLMs) like Chat Generative Pre-Trained Transformer (ChatGPT), Google Bard, and Bing AI, in research publications has raised concerns and sparked discussions within the research and academic communities.<xref rid="cit0001" ref-type="bibr">1</xref> While AI and LLMs offer potential benefits, such as improved efficiency and transformative solutions, they also present challenges related to ethical considerations, bias, fake publications, and malicious use.<xref rid="cit0002" ref-type="bibr">2</xref></p>
    <p>AI has the potential to enhance various aspects of research, including data processing, task automation, and personalized experiences.<xref rid="cit0001" ref-type="bibr">1</xref> However, AI usage in research and scientific writing can pose risks such as bias reinforcement, data privacy concerns, perpetuating data inaccuracies, and the potential for reduced critical thinking due to overreliance.<xref rid="cit0003" ref-type="bibr">3</xref> Therefore, the development of guidelines for using AI in research and scientific writing is crucial to ensure this technology’s responsible and ethical application.</p>
    <p>This editorial, published in Nature and Science of Sleep, primarily aims to enhance awareness of the evolving role of AI in research and scientific writing, emphasizing both its potential advantages and ethical challenges. By promoting responsible AI use, advocating for ethical guidelines, and engaging stakeholders, we strive to empower authors, reviewers, and the broader research community to navigate the dynamic landscape of AI in scientific writing while upholding the highest standards of integrity and credibility. Furthermore, we emphasize the critical need for the development of international guidelines that guide the responsible use of AI and LLMs in research and scientific writing.</p>
    <sec id="s0002">
      <title>AI’s Potential Benefits and Challenges</title>
      <p>AI holds the promise to profoundly transform research and education through various key advantages. Firstly, it has the capability to process vast amounts of data swiftly and efficiently, empowering researchers to navigate through sophisticated datasets and draw out meaningful insights.<xref rid="cit0001" ref-type="bibr">1</xref> Additionally, the automation features of AI streamline tasks like formatting and citation, freeing up substantial time and energy for researchers, which can then be redirected towards more complex and innovative work.<xref rid="cit0003" ref-type="bibr">3</xref>,<xref rid="cit0004" ref-type="bibr">4</xref> Lastly, AI can curate personalized learning journeys for students, tailoring the experience to their unique needs and learning preferences.<xref rid="cit0005" ref-type="bibr">5</xref></p>
      <p>Nevertheless, while promising, AI systems have notable drawbacks, especially in health and medical research. These systems can amplify and perpetuate biases present in the training data, leading to skewed predictions and potentially harmful implications for patient care.<xref rid="cit0006" ref-type="bibr">6</xref>,<xref rid="cit0007" ref-type="bibr">7</xref> This is concerning, as biases in AI models can emerge during various stages, from data collection to model evaluation.<xref rid="cit0007" ref-type="bibr">7</xref> Such biases can result in inaccurate findings that might influence clinical guidelines or medical interventions, and recent studies have underscored these concerns, suggesting that these biases can lead to significant health disparities.<xref rid="cit0008" ref-type="bibr">8</xref> Another emerging challenge is the misuse of AI by paper mills to produce fraudulent scientific papers. This abuse of AI technology has led to an increase in the volume of fake publications, undermining the credibility of scientific research.<xref rid="cit0009" ref-type="bibr">9</xref> These paper mills employ sophisticated AI tools to generate texts and images that are increasingly difficult to distinguish from authentic research, posing a significant threat to the integrity of scientific literature.<xref rid="cit0009" ref-type="bibr">9</xref></p>
      <p>Moreover, AI models, particularly those based on deep learning, are often viewed as “black boxes”; their complex inner mechanisms can be elusive, making results challenging to interpret, especially for those not versed in the domain.<xref rid="cit0010" ref-type="bibr">10</xref> Another concern, especially in academic circles, is the reliability of AI-generated text. Platforms like ChatGPT may produce content with inaccuracies or plagiarization, jeopardizing work credibility, especially if it includes false references or citation errors.<xref rid="cit0011" ref-type="bibr">11–13</xref> Additionally, although AI instruments can aid in task automation and streamline the writing process, it is important to acknowledge that these tools cannot replace the unique creativity and insight inherent in humans. AI operates by analyzing existing data and recognizing patterns; however, unlike humans, it lacks the ability to engage in unconventional thinking or to forge innovative links.</p>
    </sec>
    <sec id="s0003">
      <title>Authorship and Attribution</title>
      <p>In January 2023, Nature reported on the controversial issue of ChatGPT, an AI tool, being listed as an author on scientific and health research papers. The report highlighted that at least four articles, including two preprints and two published articles, credited ChatGPT as a co-author.<xref rid="cit0014" ref-type="bibr">14</xref> However, this practice was met with disapproval from many scientists and led to discussions about the ethical implications and the validity of AI tools being credited as authors.<xref rid="cit0015" ref-type="bibr">15</xref> Therefore, the currently accepted practice indicates that non-human AI and language models are not eligible for authorship, as they lack the ability to take responsibility for the work, provide intellectual contributions, or approve the final version of the manuscript; this consensus is shared among journals and research communities.<xref rid="cit0016" ref-type="bibr">16</xref></p>
      <p>Moreover, work generated by AI may not be subject to the rules of copyright; recently, the United States District Court for the District of Columbia confirmed that artwork generated autonomously by AI alone is not entitled to protection under the Copyright Act. This ruling is significant as it sets a precedent for those seeking to secure ownership and copyright protection for AI-generated content.<xref rid="cit0017" ref-type="bibr">17</xref> Applying these legal principles to academic work suggests that AI-generated content, even when significantly modified by human authors, might not receive the same copyright protection as work solely created by humans. This necessitates a reassessment of how AI contributions are recognized in scientific publications and calls for definitive guidelines on AI’s role in academic content creation. Such guidelines should safeguard the distinct recognition and copyright of human authorship. This ruling highlights the changing legal context of AI in academia, underscoring the need for collaboration among publishers, researchers, and legal professionals to address these emerging issues.</p>
      <p>Journals’ policies on using generative AI for scientific writing differ. Some publishers prohibit AI use without explicit editor permission, while others mandate detailed disclosure in the manuscript. Regardless of these variances, there is a consensus on the necessity for transparency and the author’s responsibility to uphold content integrity. In academia’s early AI integration phase, there is a potential stigma around AI-assisted manuscripts, even those used merely for enhancing grammar and clarity. Such manuscripts might be viewed skeptically by reviewers and readers, although there is no definitive evidence on how declaring AI assistance impacts paper acceptance. Contrary to best practices, this uncertainty may lead some authors to omit AI use disclosure. To address this potential stigma, enhancing education for all stakeholders, including authors, reviewers, and editors, is imperative. Implementing comprehensive workshops, seminars, and detailed guidelines can inform these groups about the ethical use of AI tools in academic writing, highlighting their role in augmenting human intellect and creativity rather than replacing it. Dove Press, in its author instructions, explicitly states that any AI tool assistance, including large language models for content generation, must be acknowledged.<xref rid="cit0018" ref-type="bibr">18</xref> Authors bear full responsibility for their article’s validity, originality, and integrity, and are expected to use AI tools responsibly, aligning with the publisher’s authorship ethics and editorial policies.</p>
    </sec>
    <sec id="s0004">
      <title>Detecting AI Text</title>
      <p>While publishers and editors have established various software tools for detecting similarities and plagiarism, identifying AI-generated text remains a complex challenge. The growing prevalence of AI in content creation blurs the line between human and machine authorship, raising concerns about authorship authenticity and transparency.<xref rid="cit0012" ref-type="bibr">12</xref>,<xref rid="cit0019" ref-type="bibr">19</xref>,<xref rid="cit0020" ref-type="bibr">20</xref> In response, various stakeholders in academia and publishing, such as publishers, reviewers, and editors, are increasingly turning to AI content detection tools. These tools aim to differentiate between human-written and AI-generated texts.<xref rid="cit0012" ref-type="bibr">12</xref>,<xref rid="cit0019" ref-type="bibr">19</xref> However, the effectiveness of these tools is not uniform, and ongoing research is essential to enhance their accuracy and reliability.<xref rid="cit0021" ref-type="bibr">21</xref></p>
    </sec>
    <sec id="s0005">
      <title>Towards International Guidelines</title>
      <p>As AI solutions in scientific writing rapidly evolve, there is a growing need for international guidelines that address transparency, reproducibility, and ethics in AI-assisted research and writing. These guidelines should consider both the benefits and challenges of AI and LLMs in research and education.<xref rid="cit0022" ref-type="bibr">22</xref>,<xref rid="cit0023" ref-type="bibr">23</xref> Therefore, an international statement guiding the responsible use of these technologies is urgently needed. This statement should focus on transparency, accountability, ongoing research, and risk mitigation, incorporating aspects like monitoring, evaluation, user education, and awareness. Transparency and disclosure are crucial when using AI-generated content in scientific writing.<xref rid="cit0023" ref-type="bibr">23</xref> Researchers must disclose their use of AI tools, ensuring human expertise guides the accuracy, coherence, and credibility of the content.<xref rid="cit0003" ref-type="bibr">3</xref></p>
      <p>To formulate these guidelines effectively, a consortium should be established, encompassing diverse stakeholders such as academic institutions, AI developers, legal experts, publishers, and representatives from ethics and data privacy fields. This collaborative approach will ensure comprehensive and pragmatic guidelines. The development of these guidelines should also address biases, promote fairness in AI-generated content, and consider data privacy and security, especially as AI tools often require access to large datasets, potentially containing sensitive information.<xref rid="cit0024" ref-type="bibr">24</xref></p>
      <p>Furthermore, establishing ethical guidelines for AI use in research and scientific writing is vital to maintain research integrity and ensure that scientific literature continues to be a rigorous, accurate, and innovative knowledge source.<xref rid="cit0025" ref-type="bibr">25</xref> These guidelines should ensure that AI acts as an enhancement to productivity, rather than a replacement for human effort.</p>
      <p>In creating these guidelines, it is essential to include perspectives from diverse groups.<xref rid="cit0001" ref-type="bibr">1</xref> This includes non-native English speakers who may use Language Models and AI to refine their writing, and individuals with special needs who could benefit from AI assistance. However, developing these comprehensive guidelines will likely be a time-intensive process.</p>
      <p>In summary, while AI and LLMs hold promise in research, they also bring forth challenges that demand our attention. By promoting open dialogue and implementing robust guidelines, we can ensure the ethical and responsible integration of AI and LLMs, thereby maximizing their potential benefits while mitigating risks. This editorial serves as a call to action for the authors, reviewers, and readers of Nature and Science of Sleep to prioritize responsible AI use and actively engage in ongoing discussions and policy development in the field of scientific writing.</p>
    </sec>
  </body>
  <back>
    <sec sec-type="COI-statement" id="s0006">
      <title>Disclosure</title>
      <p>The author reports no conflicts of interest in this work.</p>
    </sec>
    <ref-list>
      <title>References</title>
      <ref id="cit0001">
        <label>1.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Bahammam</surname>
<given-names>AS</given-names></string-name>, <string-name><surname>Trabelsi</surname>
<given-names>K</given-names></string-name>, <string-name><surname>Pandi-Perumal</surname>
<given-names>SR</given-names></string-name>, <string-name><surname>Jahrami</surname>
<given-names>H</given-names></string-name>. <article-title>Adapting to the Impact of Artificial Intelligence in Scientific Writing: balancing Benefits and Drawbacks while Developing Policies and Regulations</article-title>. <source><italic toggle="yes">J Nature Sci Med</italic></source>. <year>2023</year>;<volume>6</volume>(<issue>3</issue>):<fpage>152</fpage>–<lpage>158</lpage>.</mixed-citation>
      </ref>
      <ref id="cit0002">
        <label>2.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Hammad</surname>
<given-names>M</given-names></string-name>. <article-title>The Impact of Artificial Intelligence (AI) Programs on Writing Scientific Research</article-title>. <source><italic toggle="yes">Ann Biomed Eng</italic></source>
<year>2023</year>;<volume>51</volume>(<issue>3</issue>):<fpage>459</fpage>–<lpage>460</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s10439-023-03140-1</pub-id><pub-id pub-id-type="pmid">36637603</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0003">
        <label>3.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Salvagno</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Taccone</surname>
<given-names>FS</given-names></string-name>, <string-name><surname>Gerli</surname>
<given-names>AG</given-names></string-name>. <article-title>Can artificial intelligence help for scientific writing?</article-title>
<source><italic toggle="yes">Critical Care</italic></source>. <year>2023</year>;<volume>27</volume>(<issue>1</issue>):<fpage>75</fpage>. doi:<pub-id pub-id-type="doi">10.1186/s13054-023-04380-2</pub-id><pub-id pub-id-type="pmid">36841840</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0004">
        <label>4.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Pisica</surname>
<given-names>AI</given-names></string-name>, <string-name><surname>Edu</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Zaharia</surname>
<given-names>RM</given-names></string-name>, et al. <article-title>Implementing Artificial Intelligence in Higher Education: pros and Cons from the Perspectives of Academics</article-title>. <source><italic toggle="yes">Societies</italic></source>. <year>2023</year>;<volume>13</volume>(<issue>5</issue>):<fpage>118</fpage>. doi:<pub-id pub-id-type="doi">10.3390/soc13050118</pub-id></mixed-citation>
      </ref>
      <ref id="cit0005">
        <label>5.</label>
        <mixed-citation publication-type="webpage"><collab>U.S. Department of Education, O.o.E.T</collab>. <article-title>Artificial Intelligence and Future of Teaching and Learning: insights and Recommendations</article-title>; <year>2023</year>. <fpage>1</fpage>–<lpage>64</lpage>. <comment>Avaiable fron:</comment>
<ext-link xlink:href="https://tech.ed.gov/" ext-link-type="uri">https://tech.ed.gov/</ext-link>. <date-in-citation>Accessed <month>December</month>
<day>12</day>, 2023</date-in-citation>.</mixed-citation>
      </ref>
      <ref id="cit0006">
        <label>6.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Celi</surname>
<given-names>LA</given-names></string-name>, <string-name><surname>Cellini</surname>
<given-names>J</given-names></string-name>, <string-name><surname>Charpignon</surname>
<given-names>M-L</given-names></string-name>, et al. <article-title>Sources of bias in artificial intelligence that perpetuate healthcare disparities-A global review</article-title>. <source><italic toggle="yes">PLOS Digit Health</italic></source>. <year>2022</year>;<volume>1</volume>(<issue>3</issue>):<fpage>e0000022</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pdig.0000022</pub-id><pub-id pub-id-type="pmid">36812532</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0007">
        <label>7.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Mittermaier</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Raza</surname>
<given-names>MM</given-names></string-name>, <string-name><surname>Kvedar</surname>
<given-names>JC</given-names></string-name>. <article-title>Bias in AI-based models for medical applications: challenges and mitigation strategies</article-title>. <source><italic toggle="yes">NPJ Digital Med</italic></source>. <year>2023</year>;<volume>6</volume>(<issue>1</issue>):<fpage>113</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41746-023-00858-z</pub-id></mixed-citation>
      </ref>
      <ref id="cit0008">
        <label>8.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Nazer</surname>
<given-names>LH</given-names></string-name>, <string-name><surname>Zatarah</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Waldrip</surname>
<given-names>S</given-names></string-name>, et al. <article-title>Bias in artificial intelligence algorithms and recommendations for mitigation</article-title>. <source><italic toggle="yes">PLOS Digit Health</italic></source>. <year>2023</year>;<volume>2</volume>(<issue>6</issue>):<fpage>e0000278</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pdig.0000278</pub-id><pub-id pub-id-type="pmid">37347721</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0009">
        <label>9.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Liverpool</surname>
<given-names>L</given-names></string-name>. <article-title>AI intensifies fight against ‘paper mills’ that churn out fake research</article-title>. <source><italic toggle="yes">Nature</italic></source>. <year>2023</year>;<volume>618</volume>(<issue>7964</issue>):<fpage>222</fpage>–<lpage>223</lpage>. doi:<pub-id pub-id-type="doi">10.1038/d41586-023-01780-w</pub-id><pub-id pub-id-type="pmid">37258739</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0010">
        <label>10.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Linardatos</surname>
<given-names>P</given-names></string-name>, <string-name><surname>Papastefanopoulos</surname>
<given-names>V</given-names></string-name>, <string-name><surname>Kotsiantis</surname>
<given-names>S</given-names></string-name>. <article-title>Explainable AI: a Review of Machine Learning Interpretability Methods</article-title>. <source><italic toggle="yes">Entropy</italic></source>. <year>2021</year>;<volume>23</volume>(<issue>1</issue>):<fpage>18</fpage>. doi:<pub-id pub-id-type="doi">10.3390/e23010018</pub-id></mixed-citation>
      </ref>
      <ref id="cit0011">
        <label>11.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Anderson</surname>
<given-names>N</given-names></string-name>, <string-name><surname>Belavy</surname>
<given-names>DL</given-names></string-name>, <string-name><surname>Perle</surname>
<given-names>SM</given-names></string-name>, et al. <article-title>AI did not write this manuscript, or did it? Can we trick the AI text detector into generated texts? The potential future of ChatGPT and AI in Sports &amp; Exercise Medicine manuscript generation</article-title>. <source><italic toggle="yes">BMJ Open Sport Exerc Med</italic></source>. <year>2023</year>;<volume>9</volume>(<issue>1</issue>):<fpage>e001568</fpage>. doi:<pub-id pub-id-type="doi">10.1136/bmjsem-2023-001568</pub-id></mixed-citation>
      </ref>
      <ref id="cit0012">
        <label>12.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Elali</surname>
<given-names>FR</given-names></string-name>, <string-name><surname>Rachid</surname>
<given-names>LN</given-names></string-name>. <article-title>AI-generated research paper fabrication and plagiarism in the scientific community</article-title>. <source><italic toggle="yes">Patterns</italic></source>. <year>2023</year>;<volume>4</volume>(<issue>3</issue>):<fpage>100706</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.patter.2023.100706</pub-id><pub-id pub-id-type="pmid">36960451</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0013">
        <label>13.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Walters</surname>
<given-names>WH</given-names></string-name>, <string-name><surname>Wilder</surname>
<given-names>EI</given-names></string-name>. <article-title>Fabrication and errors in the bibliographic citations generated by ChatGPT</article-title>. <source><italic toggle="yes">Sci Rep</italic></source>. <year>2023</year>;<volume>13</volume>(<issue>1</issue>):<fpage>14045</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41598-023-41032-5</pub-id><pub-id pub-id-type="pmid">37679503</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0014">
        <label>14.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Stokel-Walker</surname>
<given-names>C</given-names></string-name>. <article-title>ChatGPT listed as author on research papers: many scientists disapprove</article-title>. <source><italic toggle="yes">Nature</italic></source>. <year>2023</year>;<volume>613</volume>(<issue>7945</issue>):<fpage>620</fpage>–<lpage>621</lpage>. doi:<pub-id pub-id-type="doi">10.1038/d41586-023-00107-z</pub-id><pub-id pub-id-type="pmid">36653617</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0015">
        <label>15.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Editorials</surname>
<given-names>N</given-names></string-name>. <article-title>Tools such as ChatGPT threaten transparent science; here are our ground rules for their use</article-title>. <source><italic toggle="yes">Nature</italic></source>. <year>2023</year>;<volume>613</volume>(<issue>7945</issue>):<fpage>612</fpage>. doi:<pub-id pub-id-type="doi">10.1038/d41586-023-00191-1</pub-id><pub-id pub-id-type="pmid">36694020</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0016">
        <label>16.</label>
        <mixed-citation publication-type="webpage"><collab>COPE</collab>. <article-title>Authorship and AI tools: COPE position statement</article-title>. <year>2023</year>. <comment>Available from</comment>: <ext-link xlink:href="https://publicationethics.org/cope-position-statements/ai-author#:~:text=COPE%2520position%2520statement%26text=COPE%2520joins%2520organisations%252C%2520such%2520as,responsibility%2520for%2520the%2520submitted%2520work" ext-link-type="uri">https://publicationethics.org/cope-position-statements/ai-author#:~:text=COPE%20position%20statement&amp;text=COPE%20joins%20organisations%2C%20such%20as,responsibility%20for%20the%20submitted%20work</ext-link>. <date-in-citation>Accessed <month>December</month>
<day>21</day>, 2023</date-in-citation>.</mixed-citation>
      </ref>
      <ref id="cit0017">
        <label>17.</label>
        <mixed-citation publication-type="webpage"><collab>K&amp;L Gates</collab>. <article-title>Federal Court Rules Work Generated by Artificial Intelligence Alone Is Not Eligible for Copyright Protection</article-title>. <year>2023</year>. <comment>Available from</comment>: <ext-link xlink:href="https://www.klgates.com/Federal-Court-Rules-Work-Generated-by-Artificial-Intelligence-Alone-Is-Not-Eligible-for-Copyright-Protection-8-30-2023" ext-link-type="uri">https://www.klgates.com/Federal-Court-Rules-Work-Generated-by-Artificial-Intelligence-Alone-Is-Not-Eligible-for-Copyright-Protection-8-30-2023</ext-link>. <date-in-citation>Accessed <month>December</month>
<day>21</day>, 2023</date-in-citation>.</mixed-citation>
      </ref>
      <ref id="cit0018">
        <label>18.</label>
        <mixed-citation publication-type="webpage"><collab>Dove Press. Editorial Policies/Authorship</collab>. <year>2023</year>. <comment>Available from</comment>: <ext-link xlink:href="https://www.dovepress.com/editorial-policies/authorship#:~:text=Any%2520assistance%2520from%2520AI%2520tools,integrity%2520of%2520their%2520article%2520content" ext-link-type="uri">https://www.dovepress.com/editorial-policies/authorship#:~:text=Any%20assistance%20from%20AI%20tools,integrity%20of%20their%20article%20content</ext-link>. <date-in-citation>Accessed <month>December</month>
<day>21</day>, 2023</date-in-citation>.</mixed-citation>
      </ref>
      <ref id="cit0019">
        <label>19.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Desaire</surname>
<given-names>H</given-names></string-name>, <string-name><surname>Chua</surname>
<given-names>AE</given-names></string-name>, <string-name><surname>Isom</surname>
<given-names>M</given-names></string-name>, et al. <article-title>Distinguishing academic science writing from humans or ChatGPT with over 99% accuracy using off-the-shelf machine learning tools</article-title>. <source><italic toggle="yes">Cell Rep Phys Sci</italic></source>. <year>2023</year>;<volume>4</volume>(<issue>6</issue>).</mixed-citation>
      </ref>
      <ref id="cit0020">
        <label>20.</label>
        <mixed-citation publication-type="webpage"><string-name><surname>Hosseini</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Rasmussen</surname>
<given-names>L</given-names></string-name>, <article-title>Resnik Science journals set new authorship guidelines for AI-generated text</article-title>. <source>Environmental Factor</source>; <year>2023</year>. <comment>Available from:</comment>
<ext-link xlink:href="https://factor.niehs.nih.gov/2023/3/feature/2-artificial-intelligence-ethics" ext-link-type="uri">https://factor.niehs.nih.gov/2023/3/feature/2-artificial-intelligence-ethics</ext-link>. <date-in-citation>Accessed <month>December</month>
<day>15</day>, 2023</date-in-citation>.</mixed-citation>
      </ref>
      <ref id="cit0021">
        <label>21.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Elkhatat</surname>
<given-names>AM</given-names></string-name>, <string-name><surname>Elsaid</surname>
<given-names>K</given-names></string-name>, <string-name><surname>Almeer</surname>
<given-names>S</given-names></string-name>. <article-title>Evaluating the efficacy of AI content detection tools in differentiating between human and AI-generated text</article-title>. <source><italic toggle="yes">Int J Educ Integrity</italic></source>. <year>2023</year>;<volume>19</volume>(<issue>1</issue>):<fpage>17</fpage>. doi:<pub-id pub-id-type="doi">10.1007/s40979-023-00140-5</pub-id></mixed-citation>
      </ref>
      <ref id="cit0022">
        <label>22.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Fleischmann</surname>
<given-names>C</given-names></string-name>, <string-name><surname>Aritz</surname>
<given-names>J</given-names></string-name>, <article-title>Writing the rules in AI-assisted writing</article-title>. <source><italic toggle="yes">Nature Mach Intell</italic></source>. <year>2023</year>;<volume>5</volume>(<issue>5</issue>):<fpage>469</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s42256-023-00678-6</pub-id></mixed-citation>
      </ref>
      <ref id="cit0023">
        <label>23.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Lovejoy</surname>
<given-names>CA</given-names></string-name>, <string-name><surname>Arora</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Buch</surname>
<given-names>V</given-names></string-name>, et al. <article-title>Key considerations for the use of artificial intelligence in healthcare and clinical research</article-title>. <source><italic toggle="yes">Future Healthc J</italic></source>. <year>2022</year>;<volume>9</volume>(<issue>1</issue>):<fpage>75</fpage>–<lpage>78</lpage>. doi:<pub-id pub-id-type="doi">10.7861/fhj.2021-0128</pub-id><pub-id pub-id-type="pmid">35372779</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0024">
        <label>24.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Oniani</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Hilsman</surname>
<given-names>J</given-names></string-name>, <string-name><surname>Peng</surname>
<given-names>Y</given-names></string-name>, et al. <article-title>Adopting and expanding ethical principles for generative artificial intelligence from military to healthcare</article-title>. <source><italic toggle="yes">NPJ Digital Med</italic></source>. <year>2023</year>;<volume>6</volume>(<issue>1</issue>):<fpage>225</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41746-023-00965-x</pub-id></mixed-citation>
      </ref>
      <ref id="cit0025">
        <label>25.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Smeds</surname>
<given-names>MR</given-names></string-name>, <string-name><surname>Mendes</surname>
<given-names>B</given-names></string-name>, <string-name><surname>O’Banion</surname>
<given-names>LA</given-names></string-name>, et al. <article-title>Exploring the pros and cons of using artificial intelligence in manuscript preparation for scientific journals</article-title>. <source><italic toggle="yes">J Vasc Surg Cases Innov Tech</italic></source>. <year>2023</year>;<volume>9</volume>(<issue>2</issue>):<fpage>101163</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.jvscit.2023.101163</pub-id><pub-id pub-id-type="pmid">37235171</pub-id>
</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
</pmc-articleset>
