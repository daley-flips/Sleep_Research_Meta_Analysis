<pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article">
  <?properties open_access?>
  <processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
    <restricted-by>pmc</restricted-by>
  </processing-meta>
  <front><journal-meta><journal-id journal-id-type="nlm-ta">Nat Sci Sleep</journal-id><journal-id journal-id-type="iso-abbrev">Nat Sci Sleep</journal-id><journal-id journal-id-type="publisher-id">nss</journal-id><journal-title-group><journal-title>Nature and Science of Sleep</journal-title></journal-title-group><issn pub-type="epub">1179-1608</issn><publisher><publisher-name>Dove</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmid">38894976</article-id><article-id pub-id-type="pmc">11182880</article-id><article-id pub-id-type="publisher-id">463897</article-id><article-id pub-id-type="doi">10.2147/NSS.S463897</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Research</subject></subj-group></article-categories><title-group><article-title>A Novel Continuous Sleep State Artificial Neural Network Model Based on Multi-Feature Fusion of Polysomnographic Data</article-title><alt-title alt-title-type="running-authors">Cui et al</alt-title><alt-title alt-title-type="running-title">Cui et al</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Cui</surname><given-names>Jian</given-names></name><xref rid="aff0001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="an0001" ref-type="corresp"/></contrib><contrib contrib-type="author"><name><surname>Sun</surname><given-names>Yunliang</given-names></name><xref rid="aff0002" ref-type="aff">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0009-0002-1342-3291</contrib-id><name><surname>Jing</surname><given-names>Haifeng</given-names></name><xref rid="aff0003" ref-type="aff">
<sup>3</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Qiang</given-names></name><xref rid="aff0001" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Huang</surname><given-names>Zhihao</given-names></name><xref rid="aff0001" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Qi</surname><given-names>Xin</given-names></name><xref rid="aff0001" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Cui</surname><given-names>Hao</given-names></name><xref rid="aff0001" ref-type="aff">
<sup>1</sup>
</xref></contrib><aff id="aff0001"><label>1</label><institution>Department of Big Data and Fundamental Sciences, Shandong Institute of Petroleum and Chemical Technology</institution>, <addr-line>Dongying</addr-line>, <addr-line>Shandong</addr-line>, <addr-line>257061</addr-line>, <country>People’s Republic of China</country></aff><aff id="aff0002"><label>2</label><institution>Department of Respiratory and Sleep Medicine, Bin Zhou Medical University Hospital</institution>, <addr-line>Binzhou</addr-line>, <addr-line>Shandong</addr-line>, <addr-line>256600</addr-line>, <country>People’s Republic of China</country></aff><aff id="aff0003"><label>3</label><institution>College of Software and Microelectronics, Peking University</institution>, <addr-line>Beijing</addr-line>, <addr-line>100000</addr-line>, <country>People’s Republic of China</country></aff></contrib-group><author-notes><corresp id="an0001">Correspondence: Jian Cui, <institution>Department of Big Data and Fundamental Sciences, Shandong Institute of Petroleum and Chemical Technology</institution>, <addr-line>271 Bei Er Lu</addr-line>, <addr-line>Dongying City</addr-line>, <addr-line>Shandong Province</addr-line>, <addr-line>257061</addr-line>, <country>People’s Republic of China</country>, <phone content-type="general">Tel +86-15066073763</phone>, Email jian.cui@sdipct.edu.cn</corresp></author-notes><pub-date pub-type="epub"><day>12</day><month>6</month><year>2024</year></pub-date><pub-date pub-type="collection"><year>2024</year></pub-date><volume>16</volume><fpage>769</fpage><lpage>786</lpage><history><date date-type="received"><day>12</day><month>2</month><year>2024</year></date><date date-type="accepted"><day>03</day><month>6</month><year>2024</year></date></history><permissions><copyright-statement>© 2024 Cui et al.</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Cui et al.</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/3.0/</ali:license_ref><license-p>This work is published and licensed by Dove Medical Press Limited. The full terms of this license are available at <ext-link ext-link-type="uri" xlink:href="https://www.dovepress.com/terms.php">https://www.dovepress.com/terms.php</ext-link> and incorporate the Creative Commons Attribution – Non Commercial (unported, v3.0) License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/3.0/">http://creativecommons.org/licenses/by-nc/3.0/</ext-link>). By accessing the work you hereby accept the Terms. Non-commercial uses of the work are permitted without any further permission from Dove Medical Press Limited, provided the work is properly attributed. For permission for commercial use of this work, please see paragraphs 4.2 and 5 of our Terms (<ext-link ext-link-type="uri" xlink:href="https://www.dovepress.com/terms.php">https://www.dovepress.com/terms.php</ext-link>).</license-p></license></permissions><abstract><sec><title>Purpose</title><p>Sleep structure is crucial in sleep research, characterized by its dynamic nature and temporal progression. Traditional 30-second epochs falter in capturing the intricate subtleties of various micro-sleep states. This paper introduces an innovative artificial neural network model to generate continuous sleep depth value (SDV), utilizing a novel multi-feature fusion approach with EEG data, seamlessly integrating temporal consistency.</p></sec><sec><title>Methods</title><p>The study involved 50 normal and 100 obstructive sleep apnea–hypopnea syndrome (OSAHS) participants. After segmenting the sleep data into 3-second intervals, a diverse array of 38 feature values were meticulously extracted, including power, spectrum entropy, frequency band duration and so on. The ensemble random forest model calculated the timing fitness value for all the features, from which the top 7 time-correlated features were selected to create detailed sleep sample values ranging from 0 to 1. Subsequently, an artificial neural network (ANN) model was trained to delineate sleep continuity details, unravel concealed patterns, and far surpassed the traditional 5-stage categorization (W, N1, N2, N3, and REM).</p></sec><sec><title>Results</title><p>The SDV changes from wakeful stage (mean 0.7021, standard deviation 0.2702) to stage N3 (mean 0.0396, standard deviation 0.0969). During the arousal epochs, the SDV increases from the range (0.1 to 0.3) to the range around 0.7, and decreases below 0.3. When in the deep sleep (≤0.1), the probability of arousal of normal individuals is less than 10%, while the average arousal probability of OSA patients is close to 30%.</p></sec><sec><title>Conclusion</title><p>A sleep continuity model is proposed based on multi-feature fusion, which generates SDV ranging from 0 to 1 (representing deep sleep to wakefulness). It can capture the nuances of the traditional five stages and subtle differences in microstates of sleep, considered as a complement or even an alternative to traditional sleep analysis.</p></sec></abstract><kwd-group kwd-group-type="author"><title>Keywords</title><kwd>sleep depth value</kwd><kwd>sleep continuity</kwd><kwd>EEG features</kwd><kwd>timing fitness</kwd><kwd>ANN model</kwd></kwd-group><counts><fig-count count="12"/><table-count count="2"/><ref-count count="34"/><page-count count="18"/></counts></article-meta></front>
  <body>
    <sec sec-type="intro" id="s0001">
      <title>Introduction</title>
      <p>At present, polysomnography (PSG), which can evaluate the sleep structure of patients, is the most important evaluation method for diagnosing sleep disorders such as narcolepsy and sleep apnea syndrome. PSG involves the simultaneous recording of multiple physiological parameters during sleep, including electroencephalography (EEG) to measure brain activity, electrooculography (EOG) to track eye movements, and electromyography (EMG) to assess muscle tone. Additionally, it monitors respiratory effort and airflow, heart rate, and oxygen saturation levels to detect any disruptions in breathing. These signals are crucial for identifying the specific characteristics of sleep disorders and for determining the most appropriate treatment strategies. Following the Rechtschaffen and Kales rules (R&amp;K rules), the state of PSG data (30 seconds as a period) is described as one of the five sleep stages,<xref rid="cit0001" ref-type="bibr">1</xref> which are wake (w), non-rapid eye movement period (N1, N2, N3) and rapid eye movement period (REM). However, in practice, as an insufficient description of sleep processes, also affected by subjective or objective conditions, the main drawback of R&amp;K rules is that the results can lead to a lack of consistency.<xref rid="cit0002" ref-type="bibr">2</xref> Although the sleep process can be described as one of the five sleep stages, the low temporal resolution and insufficient number of stages actually destroys the continuity of the sleep process, resulting in a rough sleep structure, which cannot reflect the sleep details when analyzing the data of sleep disorders. In recent years, the analysis of polysomnography data mostly focuses on the study of automatic sleep staging as opposed to manual methods, aiming to facilitate rapid and precise automated classification. Essentially, there are two primary approaches: the conventional machine learning method, which relies on statistical features, and the deep learning approach, grounded in various neural network architectures.</p>
      <p>In the conventional approach, the foundation of automatic sleep staging lies in the extraction of sleep features and the application of diverse classification algorithms, including support vector machines, random forests, and others.<xref rid="cit0003" ref-type="bibr">3–5</xref> The researchers selected features ranging from the time domain, frequency domain, to nonlinear characteristics for automatic sleep staging.<xref rid="cit0006" ref-type="bibr">6</xref> Multiscale entropy, which exhibited significant differences across distinct sleep stages, was selected as a key feature.<xref rid="cit0007" ref-type="bibr">7</xref> In the frequency domain, the power spectrum and power ratio of different frequency feature waves obtained through wavelet transform were excellent features.<xref rid="cit0008" ref-type="bibr">8</xref> In nonlinear features, it was found that measures such as correlation dimension, Lyapunov exponents, approximate entropy, and detrended fluctuation analysis were typical features.<xref rid="cit0009" ref-type="bibr">9</xref> In the choice of classifier models, some opted for Random Forest,<xref rid="cit0010" ref-type="bibr">10</xref> while others used Linear Discriminant Analysis (LDA),<xref rid="cit0011" ref-type="bibr">11</xref> with accuracy rates around 80% to 90%. The research above clearly shows that the cornerstone of research in automatic sleep staging lies in the analysis of characteristics derived from sleep data.</p>
      <p>Compared with the traditional approach, the deep learning methods of staging do not require strict feature extraction but highly affected by the design of neural network structure and the computing ability of the computer.<xref rid="cit0012" ref-type="bibr">12–14</xref> It could achieve an accuracy rate of 84.5% using neural networks.<xref rid="cit0015" ref-type="bibr">15</xref> The researchers employed Multilayer Perceptron (MLP) neural networks for automatic sleep staging,<xref rid="cit0016" ref-type="bibr">16</xref> reaching an accuracy rate of 74.7%. A one-dimensional convolutional network for sleep staging was proposed,<xref rid="cit0017" ref-type="bibr">17</xref> achieving an accuracy rate of 87%. Recurrent Neural Networks (RNNs) for sleep staging could reach accuracy rate of 87.2%.<xref rid="cit0018" ref-type="bibr">18</xref> A new network for sleep staging called Deepsleepnet,<xref rid="cit0019" ref-type="bibr">19</xref> which utilized two convolutional neural networks to extract time-frequency features from EEG data, combined with Long Short-Term Memory (LSTM) networks to extract associations between different sleep stages, reached an accuracy rate of 82.0%. Some researchers developed a deep learning model based on images for automatic sleep staging, using Class Activation Maps to visualize key reasoning areas,<xref rid="cit0020" ref-type="bibr">20</xref> with an accuracy rate exceeding 80%, while others employed a multimodal architecture with residual units to address the vanishing problem in deep learning,<xref rid="cit0021" ref-type="bibr">21</xref> achieving a classification accuracy rate of 87.34% and an F1-score of 87.42%. For sleep staging based on deep learning, the requirements for feature extraction are not high; however, overall, the staging accuracy results do not significantly outperform machine learning algorithms based on feature selection.</p>
      <p>Given the continuous and intricate nature of the sleep process, some researchers pointed out that relying solely on 30-second epochs to categorize it into five distinct stages could pose certain challenges in achieving accurate sleep staging.<xref rid="cit0022" ref-type="bibr">22</xref> For instance, a 30-second interval classified as wakefulness might encompass brief sleep episodes of less than 15 seconds. Once the threshold of 15 seconds is surpassed, the stage is then categorized as sleep. Conversely, in intervals designated as sleep, it was specified that any periods of wakefulness lasting less than 15 seconds were overlooked.<xref rid="cit0023" ref-type="bibr">23</xref> Additionally, the background EEG activity within the same sleep stage can exhibit significant visual differences across various periods and among different patients. Some researchers mentioned that aside from sporadic spindles or K-complexes, the EEG activity in N2 may closely resemble that of N1.<xref rid="cit0024" ref-type="bibr">24</xref></p>
      <p>Currently, these studies aim to investigate the fundamental mechanisms of sleep; however, the clinical significance of these gradual changes in the EEG remains unclear. Therefore, a measure of sleep continuity is highly beneficial for examining the intricate sleep process. For instance, patients with equivalent N2 sleep durations may exhibit substantial differences in their average sleep depth as revealed through continuity measure analysis. At present, few researchers employ continuous quantities to characterize the sleep/wake state. An EEG analysis technique has been introduced that employs a 10th-order autoregressive (AR) model to fit the EEG signal on a second-by-second basis using the Burg algorithm, which estimates AR model coefficients through the least squares method. The resulting 10 AR coefficients constitute the feature vector, which is then utilized to train a multilayer perceptron (MLP) model. The model’s output is a three-dimensional vector that represents the probabilities associated with wakefulness, REM sleep, and deep sleep.<xref rid="cit0025" ref-type="bibr">25</xref> However, the paper in question did not address the suitability of the 10 AR coefficients as features and did not consolidate the three probabilities into a unified sleep probability value, which could more accurately reflect the cohesive nature of the sleep process. In a separate study, the primary objective was to detect and quantify sleep arousals by measuring or quantifying sleep depth. This was achieved predominantly through autoregressive (AR) power spectral density (PSD) estimation to obtain the time-frequency map of the EEG signal during sleep arousals. The classification performance of potential standard signals was evaluated under various criteria using ROC curve analysis. The findings suggested that the sum of the absolute powers in the alpha and beta bands, as indicated by AUC analysis, served as a reliable continuous marker for sleep depth.<xref rid="cit0026" ref-type="bibr">26</xref> Nevertheless, this paper did not examine multiple features during the sleep process, and the AR PSD, while a valid feature extraction method, was not the sole approach. The paper acknowledges that sleep arousal is a complex phenomenon that may not be entirely defined by changes in the EEG signal’s spectral characteristics. Although ROC and AUC, based on statistical methods, can serve as markers for sleep depth, they do not inherently form a continuous model from sample data values but rather offer a data-driven analytical approach. Additionally, some researchers have developed a ratio-based index termed the odds ratio product (ORP), designed to assess the likelihood of wakefulness based on the power values of four distinct waveforms: delta, theta, alpha, and beta. This method segments the statistical samples of these four features into 10 intervals, creating 10,000 unique combinations, each with a distinct ID. Consequently, every 3-second EEG segment is assigned a specific ID, and the ratio of wakefulness to sleepiness under that ID is computed and scaled to a range between 0 and 2.5, thereby reflecting the continuous state of sleep.<xref rid="cit0027" ref-type="bibr">27</xref> While this approach allows for a more refined categorization of sleep states compared to the traditional 5-category sleep staging, it essentially provides a discrete empirical statistical samples value rather than a true continuous measure. Furthermore, the paper does not justify the choice of the four waveform power spectrum features, resulting in a shortfall in the analysis of the selected features.</p>
      <p>Among the various methods for collecting, organizing, and studying continuous representations of sleep process, many researchers have conducted more in-depth studies building on the foundation of ORP method. The product ratio method was employed to compute results as a basis for interpreting studies using novel sleep EEG biomarkers, aiding in the differentiation between insomnia and OSA.<xref rid="cit0028" ref-type="bibr">28</xref> Meanwhile, it also applied to obtain information on sleep disorders that traditional indicators could not capture.<xref rid="cit0029" ref-type="bibr">29</xref> The sleep structure types were generated to identify patients adversely affected by OSA and predicted patients whose sleep would improve with CPAP treatment.<xref rid="cit0030" ref-type="bibr">30</xref> At the same time, it was employed in sleep scoring to accurately estimate the scorer’s ability in sleep staging, and reduce inter-rater disagreement.<xref rid="cit0031" ref-type="bibr">31</xref> The product ratio method was also utilized to appraise the intervention-related alterations in non-REM sleep depth.<xref rid="cit0032" ref-type="bibr">32</xref> Some researchers employed the product ratio method and discovered a novel association between sleep depth EEG biomarkers and adolescent sleep apnea.<xref rid="cit0033" ref-type="bibr">33</xref> It was used to identify the correlation between slow wave activity in children and adolescents and the internalization of product ratio indicators.<xref rid="cit0034" ref-type="bibr">34</xref> However, all the research above has been customary to employ waveform power values as variables in the computation of a continuous index used for evaluating sleep depth. Nevertheless, compared to many other sleep characteristics, whether the timing fitness of power value features is most appropriate for the sleep depth index remains an area that requires more comprehensive investigation.</p>
      <p>In this paper, we first generate the sample values of continuous sleep depth based on the fusion of multiple features, which is an empirical value that makes no a priori assumptions about what constitutes awake or sleeping EEG patterns. Next, we train artificial neural networks using this measure samples to produce a Sleep Depth Value (SDV) and evaluate its effectiveness. The paper demonstrates that (a) the SDV accurately predicts when a patient is awake, asleep, or in an ambiguous state; (b) from the statistical samples, it is evident from the awake to N1 and N3 stages, both the mean and standard deviation of the sleep sample values and SDV progressively decrease; (c) in the same R&amp;K stage, the scale of SDV is highly variable within and between epochs and patients; and (d) the pattern of change in the SDV aligns with the occurrence of arousals, making it useful for their detection.</p>
    </sec>
    <sec id="s0002">
      <title>Methods</title>
      <sec id="s0002-s2001">
        <title>Data Processing Procedure</title>
        <p>The datasets were provided by the Department of Respiratory Sciences of Binzhou Medical College, including 50 groups of normal and 100 groups of obstructive sleep apnea–hypopnea syndrome (OSAHS), which were collected and generated by the Computerics E multi-channel sleep instrument. The total duration was around 1400 hours, including 3 EEG pathways, 2 EOG pathways, 1 EMG pathway, and other pathway signals such as electrocardiogram (ECG) and blood oxygen saturation detection. Signals were captured at a sampling rate of 256 Hz. An accomplished polysomnographic (PSG) technologist reevaluated the recordings, meticulously scoring each 30-second interval for sleep stages, arousals, and respiratory activities in compliance with the American Academy of Sleep Medicine’s standards.</p>
        <p>The algorithm was developed by Matlab R2018b with machine learning toolbox. The computer used for processing contained CPU i7-8700, 32G RAM, 2T HDD and so on. <xref rid="f0001" ref-type="fig">Figure 1</xref> presents the flow diagram, which is composed of three distinct parts:
<fig position="float" id="f0001" fig-type="figure"><label>Figure 1</label><caption><p>(<bold>A</bold>–<bold>C</bold>) Flow chart of the algorithm.</p></caption><graphic xlink:href="NSS-16-769-g0001" content-type="print-only" position="float"/></fig></p>
        <p>In part A, the pre-processing of EDF data, which includes the manual labeling of sleep stages and arousal information, is completed. This part encompasses feature extraction, standardization, and the computation of the Wake/Asleep ratio;</p>
        <p>In part B, calculating and ranking the features by the time sequence fitness firstly; Then calculating, shuffling and combining the awake/(awake + sleep) ratio as the sleep depth sample values based on the features with high timing fitness scores;</p>
        <p>In part C, based on all annotated data, we derive a comprehensive training candidate data set through multi-feature fusion and subsequently construct and evaluate an Artificial Neural Network model, which is capable of estimating the sleep depth value (SDV) for any PSG record independent of manual sleep staging and arousal labeling. The model’s efficacy is systematically validated.</p>
      </sec>
      <sec id="s0002-s2002">
        <title>Multi-Feature Selection</title>
        <p>For the EEG signal, given its weak nature and the presence of substantial background noise, it is easy to be interfered from sources such as facial muscle and eye movement activities. As a non-stationary stochastic signal, feature extraction poses a significant challenge. Consequently, following the AASM-recommended filtering criteria for each channel (bandwidth standard of the EEG signal band-pass filter set between 0.3 and 35Hz), a Butterworth filter with a passband frequency of 0.3 to 35Hz has been implemented for filtration purposes.</p>
        <p>In this paper, we selected a total of 38 time and frequency features, which are as follows, numbered from F1 to F38, in which F1 is average energy in the frequency domain, F2 to F5 are relative energy of alpha, beta, theta, and delta waves, F6 to F9 are absolute energy of alpha, beta, theta, and delta waves, F10 to F16 are ratios of band energies: delta/alpha, delta/beta, delta/theta, theta/alpha, theta/beta, alpha/beta, (delta + theta)/(alpha + beta), F17 to F21 are mean, root mean square, variance, skewness and kurtosis, F22 to F25 are duration of alpha, beta, theta, and delta bands (Short-time Fourier transform threshold settings: delta = 50μV, theta = 25μV, alpha = 25μV, beta = 25μV), F26 is spectral entropy, F27 to F30 are local mean difference values of alpha, beta, theta, and delta waves, F31 to F34 are local entropy of alpha, beta, theta, and delta waves, F35 to F38 are maximum amplitude values of alpha, beta, theta, and delta bands.</p>
        <p>In this study, we employed a random forest model with all 38 features to evaluate the temporal consistency between input features and manually annotated sleep stages. The model’s construction process, which involves the random selection of features from multiple decision trees, places significant emphasis on the number of segmentation points a feature can provide as a key measure of its classification accuracy. A higher number of segmentation points indicate greater significance for the feature. Throughout the training process, we meticulously documented various metrics, including the total number of feature splits and total information gain, with an average calculated over multiple iterations to quantify the temporal consistency of the features. Notably, Features 6 through 9, representing the power value characteristics of alpha, beta, theta, and delta waves, exhibited pronounced temporal characteristics, with the beta wave feature being particularly notable for its high timing fitness. After thorough analysis and scoring, we identified Feature 7 (Absolute energy of beta waves), Feature 14 (The ratio of energy bands for theta to beta), Feature 18 (Root mean square of the signal), Feature 23 (Duration of the beta band with a short-time Fourier transform threshold setting of 25μV), Feature 26 (Spectral entropy), Feature 32 (Local entropy of beta), and Feature 33 (Local entropy of theta) as having a high temporal fit, making them particularly relevant for the temporal consistency analysis of sleep stages. These findings are illustrated in <xref rid="f0002" ref-type="fig">Figure 2</xref>, which provides an analytical chart focusing on the temporal consistency of the 38 features, highlighting the estimations of these specific features.
<fig position="float" id="f0002" fig-type="figure"><label>Figure 2</label><caption><p>Multi-feature selection based on timing fitness.</p></caption><graphic xlink:href="NSS-16-769-g0002" content-type="print-only" position="float"/></fig></p>
      </sec>
      <sec id="s0002-s2003">
        <title>Calculation of SDV Sample Values</title>
        <p>First, during data processing, each 3-second period is marked as wakefulness or sleep; specifically, phase W and the period contain arousal are categorized as wakefulness, while all other stages are considered sleep; second, to analyze sleep data with multiple features, we begin with selecting the basic waveform energy value feature as the foundation for statistical distribution, which are divided into 10 equal sample intervals, and formed a variety of energy combination values for the four fundamental waveforms: alpha, beta, theta, and delta; third, for each waveform power combination value, we count the number of occurrences corresponding to wakefulness and sleep, and then calculate the ratio of wakefulness to the sum of sleep and wakefulness, which serves as the baseline value for sleep depth; Fourth, after building on this baseline value, the temporal consistency of multiple features is considered and the top N features (in this case, temporarily set at 7) are selected to compute a ranked combination based on the characteristic values of these N features. Each combination will comprise several baseline sleep depth values; fifth, to obtain a representative SDV sample value after feature fusion for an N-feature combination, we weigh each feature by its temporal consistency degree and calculate the weighted average. This approach ensures that features with higher temporal consistency contribute more significantly to the final sleep depth estimation.</p>
        <p><xref rid="t0001" ref-type="table">Table 1</xref> is the statistical result of the SDV sample values of all the data, including the average numbers of 3-second period, percentages of total, the mean and standard deviation of SDV sample values in each sleep stages. In <xref rid="t0001" ref-type="table">Table 1</xref>, as sleep stages change from Awake to N3, the mean value of the SDV samples decreases from 0.7 to 0.03, and the variance drops from approximately 0.27 to around 0.09. This indicates that the closer to the awake state, the greater the fluctuation in sleep depth, whereas proximity to deep sleep is associated with less variability. Moreover, during the REM stage, both the mean and variance of the Sleep Depth Value (SDV) samples increase in comparison to those in the N3 stage, indicating that arousals contribute to fluctuations in the sleep process, which aligns with observations from real-world sleep patterns.<table-wrap position="float" id="t0001"><label>Table 1</label><caption><p>Statistical Results of the Sleep Depth Sample Values</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1">Sleep Stages</th><th rowspan="1" colspan="1">Mean of # 3s Epochs/Patient</th><th rowspan="1" colspan="1">Std of # 3s Epochs/Patient</th><th rowspan="1" colspan="1">Percentage in Total (%)</th><th rowspan="1" colspan="1">Mean of SDV</th><th rowspan="1" colspan="1">Std of SDV</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Awake</td><td rowspan="1" colspan="1">2397</td><td rowspan="1" colspan="1">1645</td><td rowspan="1" colspan="1">24.87</td><td rowspan="1" colspan="1">0.7021</td><td rowspan="1" colspan="1">0.2702</td></tr><tr><td rowspan="1" colspan="1">N1</td><td rowspan="1" colspan="1">803</td><td rowspan="1" colspan="1">672</td><td rowspan="1" colspan="1">8.33</td><td rowspan="1" colspan="1">0.2353</td><td rowspan="1" colspan="1">0.2709</td></tr><tr><td rowspan="1" colspan="1">N2</td><td rowspan="1" colspan="1">3380</td><td rowspan="1" colspan="1">1067</td><td rowspan="1" colspan="1">35.07</td><td rowspan="1" colspan="1">0.1202</td><td rowspan="1" colspan="1">0.1907</td></tr><tr><td rowspan="1" colspan="1">N3</td><td rowspan="1" colspan="1">1664</td><td rowspan="1" colspan="1">486</td><td rowspan="1" colspan="1">17.27</td><td rowspan="1" colspan="1">0.0396</td><td rowspan="1" colspan="1">0.0969</td></tr><tr><td rowspan="1" colspan="1">REM</td><td rowspan="1" colspan="1">1393</td><td rowspan="1" colspan="1">567</td><td rowspan="1" colspan="1">14.46</td><td rowspan="1" colspan="1">0.1847</td><td rowspan="1" colspan="1">0.2043</td></tr></tbody></table><table-wrap-foot><fn id="tfn0001"><p><bold>Notes</bold>: Results expressed as arithmetic mean and standard deviations. “Mean and Std of # 3s epochs/patient” and “Percentage in Total” are calculated based on the manual labeled data. “Mean and Std of SDV” are calculated based on sleep depth sample values.</p></fn><fn id="tfn0002"><p><bold>Abbreviations</bold>: # 3s epochs/patient, Number of 3s epochs per patient; SDV, Sleep Depth Value; Std, Standard Deviation.</p></fn></table-wrap-foot></table-wrap></p>
        <p><xref rid="t0001" ref-type="table">Table 1</xref> shows the statistical results of sleep depth sample values. However, for different EEG data sets, the results will differ. <xref rid="f0003" ref-type="fig">Figure 3</xref> is the sequence diagram of SDV sample values after multi-feature fusion finally generated from specific EEG data. In <xref rid="f0003" ref-type="fig">Figure 3</xref>, (a) is the manually calibrated sleep staging map, and (b) is the generated SDV sample value map for every 3 seconds. It can be seen from the above figure that the sample value of sleep depth calculated according to 3 seconds can basically reflect the continuity of the sleep process. From phase W to phase N3, it is a continuously changing process. In phase N3 and phase N2, it can be seen that the sleep depth values are convex, which can reflect the change of sleep depth during sleep. Even in the same sleep period, the sleep depth values are different. If we only consider the sleep stages, we cannot see the changes in sleep during a certain sleep period.
<fig position="float" id="f0003" fig-type="figure"><label>Figure 3</label><caption><p>Comparison between sleep depth samples and sleep stages. (<bold>a</bold>) is the manually calibrated sleep staging map, with the horizontal axis representing time points (a point every 3 seconds), and the vertical axis representing sleep stages; (<bold>b</bold>) is the SDV sample values map for every 3 seconds.</p></caption><graphic xlink:href="NSS-16-769-g0003" content-type="print-only" position="float"/></fig></p>
        <p>From a statistical perspective, we combine the manually marked sleep staging results and sleep depth sample values after multi-feature fusion. The distribution of sample values in different sleep stages is counted, and the results are shown in <xref rid="f0004" ref-type="fig">Figure 4</xref>. The x-axis is mapped to the various sleep stages, namely Wake (W), N1, N2, N3, and REM, whereas the y-axis depicts the corresponding values for sleep depth, scaled from 0 to 1. Within this spectrum, a value of 0 signifies the deepest sleep, and a value of 1 denotes the state of complete wakefulness. It can be seen from the figure that the distribution range of sample values of sleep depth in phase W is 0.7–1, with an average above 0.8, 0.1–0.4 in phase N1, with an average of about 0.3, 0–0.2 in phase N2, with an average of about 0.12, 0–0.08 in phase N3, with an average of under 0.05, 0.15–0.3 in phase REM, with an average of about 0.2. The statistical results from a single data set differ from those of multiple data sets in <xref rid="t0001" ref-type="table">Table 1</xref> particularly in terms of mean and variance. It is also evident that there are some outliers in different sleep stages, which are directly related to the individuals being tested. Therefore, it is necessary to establish an accurate SDV prediction model based on the statistical sleep depth samples.
<fig position="float" id="f0004" fig-type="figure"><label>Figure 4</label><caption><p>Statistical result of sleep depth samples.</p></caption><graphic xlink:href="NSS-16-769-g0004" content-type="print-only" position="float"/></fig></p>
      </sec>
      <sec id="s0002-s2004">
        <title>Development of the ANN Model</title>
        <p>From the above discussion, it is evident that statistical sample values of sleep depth are generated based on feature values with strong time correlation. The relationship between the results under multiple feature fusion and the features themselves is very complex and not linear. Therefore, establishing a joint distribution model for multiple random variables from a mathematical perspective is extremely challenging. In this paper, we opt to construct and train an artificial neural network model to predict sleep depth values (SDV).</p>
        <p>Utilizing the SDV sample values, a selection of multiple features with high temporal coherence is treated as random variables. An Artificial Neural Network (ANN) is constructed, where the feature values serve as inputs and the corresponding SDV samples serve as outputs for model training. The architecture comprises seven neurons in the input layer, corresponding to the chosen features, two hidden layers each with six neurons, and an output layer with a single neuron representing the SDV value ranging from 0 to 1. The training parameters are set with a maximum iteration count of 1000, a target error of 10<sup>−5</sup>, a learning rate of 0.01, and a momentum coefficient of 0.9. As depicted in <xref rid="f0005" ref-type="fig">Figure 5</xref>, the error distribution for training data, validation data, and test data is confined between −0.0392 and 0.0432, suggesting the efficacy of the proposed model.
<fig position="float" id="f0005" fig-type="figure"><label>Figure 5</label><caption><p>Error histogram of ANN model.</p></caption><graphic xlink:href="NSS-16-769-g0005" content-type="print-only" position="float"/></fig></p>
      </sec>
    </sec>
    <sec id="s0003">
      <title>Results</title>
      <p>The result of sleep depth values (SDV) based on multi-feature fusion from the ANN model is validated mainly in the following three aspects:</p>
      <sec id="s0003-s2001">
        <title>Verification of ANN Model</title>
        <p><xref rid="f0006" ref-type="fig">Figure 6</xref> illustrates a comparison between the sleep depth values predicted by the ANN model and those that are manually staged. The figure reveals that the predictions generated by the sleep depth model more accurately reflect the changes in sleep continuity compared to the manually labeled data. Notably, even within stable sleep stages, there are fluctuations in the predicted sleep depth values, aligning with the natural fluctuations observed in the sleep process.
<fig position="float" id="f0006" fig-type="figure"><label>Figure 6</label><caption><p>Prediction result of ANN model. (<bold>a</bold>) is the manually calibrated sleep staging map, with the horizontal axis representing time points (a point every 1 seconds), and the vertical axis representing sleep stages; (<bold>b</bold>) is the sleep depth values predicted by the ANN model.</p></caption><graphic xlink:href="NSS-16-769-g0006" content-type="print-only" position="float"/></fig></p>
        <p><xref rid="f0007" ref-type="fig">Figure 7</xref> enlarges the details of the part between 500 and 3500 seconds in <xref rid="f0006" ref-type="fig">Figure 6</xref>. The progression of the overall sleep process is clearly delineated, transitioning from Awake through N1 and N2 stages, ultimately reaching deep N3 sleep as depicted by the sleep depth values. Initially, during the Awake stage, the SDV (Sleep Depth Value) gradually descends from approximately 0.8 to around 0.6. Between 2000 and 2500 seconds, despite the SDV momentarily dipping below 0.6, it experiences an upward trend, while the sleep stage remains labeled as Awake. This suggests that even within the wakeful state, there are varying intensities of sleepiness. At around 2500 seconds, a sharp decline in SDV signifies the onset of N1 sleep. However, the subsequent rise in SDV between 2500 and 2600 seconds does not surpass 0.45, indicating a stabilization within the N1 phase. Around 2600 seconds, the SDV plunges further to 0.2, indicative of entry into the N2 stage, yet at roughly 2700 seconds, it ascends to 0.4, causing a temporary reversion from N2 back to N1. Following this fluctuation, the SDV swiftly decreases and stabilizes beneath 0.1, transitioning from N1 back to N2 before advancing into N3 sleep. This analysis reveals that the model’s predictions concerning sleep depth values offer a more nuanced perspective of sleep compared to conventional sleep staging, uncovering significant variances in sleep depth even within identical stages.
<fig position="float" id="f0007" fig-type="figure"><label>Figure 7</label><caption><p>Details of prediction result. (<bold>a</bold>) is the details between 500–3500 seconds of manually sleep staging result; (<bold>b</bold>) is the details between 500–3500 seconds of sleep depth values predicted by the ANN model.</p></caption><graphic xlink:href="NSS-16-769-g0007" content-type="print-only" position="float"/></fig></p>
      </sec>
      <sec id="s0003-s2002">
        <title>Verification Based on Machine Learning</title>
        <p>The SDV outcomes derived from the ANN model based on the multi-feature fusion serve as the input layer, while the manually labeled sleep stage data constitute the output layer. The machine learning algorithm is trained using a 10-fold cross-validation approach (with 90% allocated for training and 10% for testing) to validate its efficacy. Given that the classification labels are W, N1, N2, N3, and REM, and there is a considerable disparity in the quantity of data across different classes, leading to an imbalance, the enhanced MSMOTE algorithm is employed for oversampling to create a balanced dataset for model training. Then, this paper initially applies KNN, Random Forest and SVM classifier to classify the data segmented into 3-second intervals, followed by a refinement of the results using the Hidden Markov Model (HMM). It is found that these three classification models derived from three-second intervals exhibit numerous burrs. This is attributable to the brevity of the three-second epochs. One 30-second epoch can be labeled with one sleep stage, while the ten 3-second periods it contains may have different sleep stages. These three classification models also fail to encapsulate the transitional relationships between consecutive time periods. Therefore, for comparison with the manual sleep staging based on 30-second epochs, this paper aggregated every ten 3-second outcomes to produce a 30-second staging result. Then, the sleep staging results are processed using the Hidden Markov Model (HMM), which is capable of handling data with time-series characteristics. The HMM takes the sleep states (Awake, N1, N2, N3, and REM) and the observed data (polysomnograms) as training data, learning the transition patterns between different sleep states and the distribution of the observed data under each state, ensuring that the results align with the temporal sequence properties of sleep staging. The results of the validation process are depicted in <xref rid="f0008" ref-type="fig">Figure 8</xref>, with the SVM model serving as an illustrative example. The first diagram represents the manually annotated sleep stage, the second displays the SVM-classified stages based on three-second epochs, and the third presents the outcome following HMM refinement of the SVM results.
<fig position="float" id="f0008" fig-type="figure"><label>Figure 8</label><caption><p>Sleep staging result based on SDV. (<bold>a</bold>) is the manually calibrated sleep staging map, with the horizontal axis representing time points (a point every 3 seconds), and the vertical axis representing sleep stages; (<bold>b</bold>) is the SVM-classified stages result based on 3-second epochs; (<bold>c</bold>) is the result of SVM refined by HMM model.</p></caption><graphic xlink:href="NSS-16-769-g0008" content-type="print-only" position="float"/></fig></p>
        <p>In <xref rid="t0002" ref-type="table">Table 2</xref>, the average accuracy and standard deviation of the classification results for different sleep stages by different algorithms are, respectively, summarized, along with the overall average accuracy and overall standard deviation. From the perspective of different sleep stages, the accuracy rate for the Awake stage is high overall, and slightly improves after HMM correction; the determination of the N1 stage has the lowest accuracy rate, which significantly improves after HMM correction but is still the lowest compared to other stages, not exceeding 50%. However, since the N1 stage does not occupy a high proportion of the sleep process, its impact on the final accuracy is not significant; the mean and std of accuracy results of N2 are both higher than N3 stages; the REM stage is distinguished with the aid of eye movement signals, and the accuracy rate can reach 89% after HMM correction. It can be seen from <xref rid="t0002" ref-type="table">Table 2</xref> that using only KNN, Random Forest, and SVM algorithms, the total accuracy rate does not exceed 81%, and the accuracy can be improved by about 10% after correction with the HMM algorithm; on the whole, the accuracy rate is highest after correction with the SVM combined with the HMM algorithm, reaching 90.07%. This indicates that due to the characteristic of SDV values that can reflect the details of the sleep process, simple classification algorithms can achieve effective automatic sleep staging.<table-wrap position="float" id="t0002"><label>Table 2</label><caption><p>Accuracy Results of Sleep Stage Classification</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="1" colspan="1">Sleep Stages<break/>Algorithm</th><th rowspan="1" colspan="1">Awake Accuracy</th><th rowspan="1" colspan="1">N1 Accuracy</th><th rowspan="1" colspan="1">N2 Accuracy</th><th rowspan="1" colspan="1">N3 Accuracy</th><th rowspan="1" colspan="1">REM Accuracy</th><th rowspan="1" colspan="1">Total Accuracy</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">KNN (mean)</td><td rowspan="1" colspan="1">85.66%</td><td rowspan="1" colspan="1">17.10%</td><td rowspan="1" colspan="1">70.44%</td><td rowspan="1" colspan="1">63.02%</td><td rowspan="1" colspan="1">60.11%</td><td rowspan="1" colspan="1">67.01%</td></tr><tr><td rowspan="1" colspan="1">KNN (std)</td><td rowspan="1" colspan="1">0.0751</td><td rowspan="1" colspan="1">0.1031</td><td rowspan="1" colspan="1">0.136</td><td rowspan="1" colspan="1">0.2231</td><td rowspan="1" colspan="1">0.1596</td><td rowspan="1" colspan="1">0.0614</td></tr><tr><td rowspan="1" colspan="1">Random Forest (mean)</td><td rowspan="1" colspan="1">91.02%</td><td rowspan="1" colspan="1">25.09%</td><td rowspan="1" colspan="1">76.87%</td><td rowspan="1" colspan="1">63.69%</td><td rowspan="1" colspan="1">62.97%</td><td rowspan="1" colspan="1">71.79%</td></tr><tr><td rowspan="1" colspan="1">Random Forest (std)</td><td rowspan="1" colspan="1">0.0811</td><td rowspan="1" colspan="1">0.0732</td><td rowspan="1" colspan="1">0.106</td><td rowspan="1" colspan="1">0.2091</td><td rowspan="1" colspan="1">0.1329</td><td rowspan="1" colspan="1">0.057</td></tr><tr><td rowspan="1" colspan="1">SVM (mean)</td><td rowspan="1" colspan="1">95.63%</td><td rowspan="1" colspan="1">20.30%</td><td rowspan="1" colspan="1">87.82%</td><td rowspan="1" colspan="1">78.74%</td><td rowspan="1" colspan="1">73.29%</td><td rowspan="1" colspan="1">80.47%</td></tr><tr><td rowspan="1" colspan="1">SVM (std)</td><td rowspan="1" colspan="1">0.0751</td><td rowspan="1" colspan="1">0.0908</td><td rowspan="1" colspan="1">0.1302</td><td rowspan="1" colspan="1">0.236</td><td rowspan="1" colspan="1">0.1825</td><td rowspan="1" colspan="1">0.0696</td></tr><tr><td rowspan="1" colspan="1">KNN+HMM (mean)</td><td rowspan="1" colspan="1">90.30%</td><td rowspan="1" colspan="1">34.06%</td><td rowspan="1" colspan="1">78.69%</td><td rowspan="1" colspan="1">79.19%</td><td rowspan="1" colspan="1">78.12%</td><td rowspan="1" colspan="1">77.87%</td></tr><tr><td rowspan="1" colspan="1">KNN+HMM (std)</td><td rowspan="1" colspan="1">0.0795</td><td rowspan="1" colspan="1">0.2017</td><td rowspan="1" colspan="1">0.1866</td><td rowspan="1" colspan="1">0.2542</td><td rowspan="1" colspan="1">0.1912</td><td rowspan="1" colspan="1">0.0822</td></tr><tr><td rowspan="1" colspan="1">Random Forest+HMM (mean)</td><td rowspan="1" colspan="1">91.16%</td><td rowspan="1" colspan="1">40.47%</td><td rowspan="1" colspan="1">85.50%</td><td rowspan="1" colspan="1">79.07%</td><td rowspan="1" colspan="1">82.07%</td><td rowspan="1" colspan="1">81.55%</td></tr><tr><td rowspan="1" colspan="1">Random Forest+HMM (std)</td><td rowspan="1" colspan="1">0.0892</td><td rowspan="1" colspan="1">0.2433</td><td rowspan="1" colspan="1">0.1682</td><td rowspan="1" colspan="1">0.2588</td><td rowspan="1" colspan="1">0.1772</td><td rowspan="1" colspan="1">0.0925</td></tr><tr><td rowspan="1" colspan="1">SVM+HMM (mean)</td><td rowspan="1" colspan="1">98.12%</td><td rowspan="1" colspan="1">39.01%</td><td rowspan="1" colspan="1">95.26%</td><td rowspan="1" colspan="1">93.33%</td><td rowspan="1" colspan="1">89.12%</td><td rowspan="1" colspan="1">90.07%</td></tr><tr><td rowspan="1" colspan="1">SVM+HMM (std)</td><td rowspan="1" colspan="1">0.076</td><td rowspan="1" colspan="1">0.158</td><td rowspan="1" colspan="1">0.1793</td><td rowspan="1" colspan="1">0.2558</td><td rowspan="1" colspan="1">0.2008</td><td rowspan="1" colspan="1">0.0805</td></tr></tbody></table><table-wrap-foot><fn id="tfn0003"><p><bold>Notes</bold>: Results expressed as accuracy between the ground truth and the sleep stages prediction generated by K-Nearest Neighbors, Random Forest, and Support Vector Machine. The Hidden Markov Model method is used to improve the result from these three algorithms.</p></fn><fn id="tfn0004"><p><bold>Abbreviations</bold>: KNN, K-Nearest Neighbors; SVM, Support Vector Machine; HMM, Hidden Markov Model.</p></fn></table-wrap-foot></table-wrap></p>
      </sec>
      <sec id="s0003-s2003">
        <title>Verification Based on the Arousal Recognition</title>
        <p>During N1, N2, N3, or REM sleep stages, if there is a sudden alteration in EEG frequency—including alpha, theta, or any EEG wave with a frequency exceeding 16Hz (excluding spindle waves) with a duration surpassing 3 seconds, and this shift occurs after at least 10 seconds of stable sleep, it can be manually identified as an arousal. If it happens during the REM phase, there should also be a concomitant increase in the amplitude of submental electromyography that persists for no less than 1 second. In this paper, the sleep depth values of several sets of data at the artificially marked arousal points are computed. The arousal segment encompasses the 3-second period of the arousal duration itself, along with the initial 12 seconds and the final 3 seconds, totaling 18 seconds in duration.</p>
        <p>First of all, the alteration in sleep depth at the point of arousal should conform to a pattern that progresses from the lower SDV of sleep states, to the elevated values indicative of an arousal state, and subsequently back to the reduced values associated with sleep states. In this paper, 100 instances of manually marked arousal signals are randomly chosen for comparison with 100 signals captured during non-wake periods in N1, N2, N3, and REM phases to contrast the varying patterns of SDV changes. This comparative analysis is depicted in <xref rid="f0009" ref-type="fig">Figure 9</xref>. The pattern of sleep depth value changes during arousal generally aligns with the anticipated judgment criteria. The mean value of the sleep depth during arousal can exceed 0.7, and there is a gradual increase in sleep depth values from 0.1 to 0.3 within the 10 seconds preceding an arousal, which is a continuous process of change and increment that reflects the described continuity of sleep depth variation. Post-awakening, the sleep depth values progressively descend below 0.3, with the period of sleep depth values remaining above 0.3 lasting approximately 6 seconds.
<fig position="float" id="f0009" fig-type="figure"><label>Figure 9</label><caption><p>Statistical result of SDV in arousal period.</p></caption><graphic xlink:href="NSS-16-769-g0009" content-type="print-only" position="float"/></fig></p>
        <p>Secondly, 100 arousal signals and 100 non-arousal sleep signals, each with a duration of 18 seconds, are randomly chosen. The respective average sleep depth values from the previously mentioned segment (illustrated in <xref rid="f0009" ref-type="fig">Figure 9</xref>) are utilized as benchmark templates for wakefulness and non-wakefulness states, respectively. Simultaneously, an additional randomized selection is executed without replacement from the available data to compile a validation dataset composed of 100 arousal signals and 100 non-arousal sleep signals. Then, the correlation between each 18-second signal in the validation dataset and the sleep depth value templates for wakefulness and non-wakefulness is calculated by utilizing the Pearson correlation coefficient as a measure of similarity. This coefficient is scaled from −1 to 1, where −1 denotes a negative correlation, 1 signifies a positive correlation, and 0 represents an absence of correlation. Subsequently, an SVM classification model is then trained using these signal sleep depth values in a 5-fold cross-validation scheme to verify the accuracy in discerning whether signals indicate arousal. The detailed results are exhibited in <xref rid="f0010" ref-type="fig">Figure 10</xref>, which illustrates the correlation between signals and non-wakefulness templates on the abscissa, contrasted with the ordinate showing the correlation between signals and wakefulness templates. The blue circles denote the 100 arousal signals, while the red dots represent the 100 non-arousal signals. The delineation is provided by the classification line derived from the support vector machine employing a Gaussian kernel. Employing a 5-fold cross-validation method yields an average accuracy rate for arousal determination of 87.21%. This indicates that the sleep depth value effectively mirrors key elements of the sleep process and exhibits a robust capacity for identifying arousal signals.
<fig position="float" id="f0010" fig-type="figure"><label>Figure 10</label><caption><p>Arousal detection based on SDV pattern recognition.</p></caption><graphic xlink:href="NSS-16-769-g0010" content-type="print-only" position="float"/></fig></p>
        <p>Furthermore, as illustrated in <xref rid="f0002" ref-type="fig">Figure 2</xref>, which depicts the timing fitness of sleep stages, this paper selects two features that are the most prominent: the duration of the frequency band for beta waves (feature number 23) and the local entropy for theta waves (feature number 33). Since the range of values for each feature is not uniform, standardization is performed to map to the range with a mean of 0 and a standard deviation of 1. The comparison of two feature value patterns during arousal and non-arousal sleep states is presented in <xref rid="f0011" ref-type="fig">Figure 11</xref>. The feature of duration of the frequency band for beta waves (feature number 23) is positively correlated with the arousal template, whereas the local entropy for theta waves (feature number 33) is negatively correlated. Both features are largely unrelated to the non-arousal signal.
<fig position="float" id="f0011" fig-type="figure"><label>Figure 11</label><caption><p>Comparison between two features in arousal period. (<bold>a</bold>) is the correlation between the frequency band for beta waves (feature number 23) and the arousal template; (<bold>b</bold>) is the correlation between the local entropy for theta waves (feature number 33) and the arousal template.</p></caption><graphic xlink:href="NSS-16-769-g0011" content-type="print-only" position="float"/></fig></p>
        <p>At the same time, this paper contrasts the likelihood of arousal during sleep between individuals with normal sleep patterns and patients with obstructive sleep apnea (OSA) in <xref rid="f0012" ref-type="fig">Figure 12</xref>. When the sleep depth value falls below 0.1 (indicating a state of deep sleep), the likelihood of arousal during sleep in individuals with normal sleep patterns is relatively low, exhibiting an average probability of less than 10%. Conversely, the mean arousal probability in OSA patients approximates 30%, aligning with the clinical observation that these patients frequently experience arousals and microarousals during sleep, which disrupts the normal sleep architecture and significantly diminishes sleep efficiency. Furthermore, regardless of normal sleep data or OSA sleep data, there is a pervasive trend: as the sleep depth value ascends (ranging from 0 to 1, indicating the transition from deep sleep to light sleep and then to wakefulness), the probability of arousal/wakefulness progressively increases.
<fig position="float" id="f0012" fig-type="figure"><label>Figure 12</label><caption><p>Arousal &amp; awake probability between normal and OSA. (<bold>a</bold>) represents the probability of experiencing arousal during sleep for individuals with normal sleep patterns; (<bold>b</bold>) denotes the likelihood of arousal events occurring during sleep in individuals diagnosed with obstructive sleep apnea (OSA).</p></caption><graphic xlink:href="NSS-16-769-g0012" content-type="print-only" position="float"/></fig></p>
      </sec>
    </sec>
    <sec id="s0004">
      <title>Discussion</title>
      <p>This paper establishes an artificial neural network model based on the sample values generated by the fusion of multiple sleep features. This model produces continuous sleep depth values (SDVs) ranging from 0 to 1, according to the multi-feature values at different time points during sleep. In doing so, we utilized a comprehensive set of features, including time-domain attributes, frequency-domain elements, and other relevant characteristics. The resulting sleep depth values generated by the model are capable of measuring the continuous variations in sleep depth and reflecting various aspects of sleep quality, such as the arousal/wakefulness index, the distribution of durations across different sleep stages, and overall sleep efficiency. During the development and validation of this model, it was found that the method of this paper has the following advantages:
<list list-type="order"><list-item><p>Continuous Measurement: Unlike traditional sleep staging methods, which categorize sleep into discrete stages, this ANN model provides a continuous scale of sleep depth values (SDV) ranging from 0 (deep sleep) to 1 (wakefulness). Specifically, SDVs from 0 to 0.3 are associated with sleep, those ranging from 0.3 to 0.6 denote periods of unstable sleep, and values from 0.6 to 1 are indicative of wakefulness. This nuanced scale affords a more refined and granular insight into the dynamics of sleep state transitions and the subtleties of sleep patterns.</p></list-item><list-item><p>High Accuracy: The model demonstrates high accuracy in distinguishing between different sleep states, particularly in identifying wakefulness and deep sleep, which is crucial for applications where precise sleep state identification is necessary.</p></list-item><list-item><p>Accurate Arousal Measurement: The SDV is closely associated with the arousal/wakefulness index, making it a reliable indicator for predicting the transition between sleep states and the stability of sleep.</p></list-item><list-item><p>Flexible Model Application: The ANN model can be easily adapted to new data, enhancing its versatility. It can also function without additional training data, providing immediate sleep depth values that can streamline the process of sleep staging.</p></list-item><list-item><p>Potential for Real-Time Monitoring: With the ANN model, there is the possibility of real-time monitoring of sleep patterns, which could be particularly useful in clinical settings for assessing alertness levels or managing sedation during medical procedures.</p></list-item></list></p>
      <p>Its disadvantages are:</p>
      <p>Dependence on Technical Factors: The quality of the SDV calculation can be influenced by the data acquisition system and the algorithms used for signal processing, which may introduce variability or bias into the results.</p>
      <p>Limitations in Application Process include:
<list list-type="order"><list-item><p>Individual Differences: Although the Sleep Depth Value (SDV) demonstrates a strong correlation with sleep depth and arousability, there may be significant variability in SDV values among different individuals, which could affect the model’s ability to generalize across a diverse population. Further research may be needed to establish a normal range for SDV values.</p></list-item><list-item><p>Differentiation Between REM and NREM Sleep: Accurately differentiating between REM and NREM sleep stages may require additional data, such as electrooculogram (EOG) electrode readings, which are not considered within the scope of the current model.</p></list-item><list-item><p>Adaptability to Specific Applications: While the model shows promise in a controlled laboratory environment, its effectiveness in real-world applications, such as home monitoring or the treatment of sleep disorders, has yet to be fully determined and may require further validation.</p></list-item></list></p>
    </sec>
    <sec id="s0005">
      <title>Conclusion</title>
      <p>This paper presents a pioneering design and calculation of the temporal fit of multiple features, forming statistical sample values of sleep depth based on feature values. It innovatively proposes and trains an artificial neural network model that can produce continuous sleep depth values ranging from 0 to 1 at any given moment (non-discrete values) and has validated the effectiveness of the model through various forms of verification. This model of sleep continuity can capture the nuances of the traditional five-stage classification method (W, N1, N2, N3, and REM) and subtle differences in microstates of sleep, considered as a complement or even an alternative to traditional sleep analysis. However, further research is needed to integrate it with other clinical outcomes.</p>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      <p>This study was supported the project of Shandong University Scientific Research Development Program (Grant No. J18KB071), Dongying Science and Technology Development Fund (Grant No. DJB2021010), Shandong Province Undergraduate Teaching Reform Research Project (Grant No. Z2021209 and Grant No. Z2023239) and Dongying Key Laboratory of Intelligent Information Processing and Sub-laboratory of Artificial Intelligence and Data Mining. Yunliang Sun and the Respiratory Department of Binzhou Medical University Hospital provided the data and gave a great help for paper writing and revision.</p>
      <p>This paper has been facilitated and supported by the Biomedical Research Ethics Committee of Binzhou Medical University Affiliated Hospital: (1) Detailed explanations of the study were provided to participants, including the purpose, procedures, expected duration, potential risks and benefits, and any possible compensation. (2) Participants were ensured a full understanding of the information provided and had the opportunity to ask questions and discuss their concerns. (3) Voluntary participation was ensured, with participants knowing they could choose not to participate in the study or withdraw at any time without adverse consequences. (4) Completion of Patient Written Informed Consent. Prior to the commencement of the study, all participants were required to sign a written informed consent form. This form detailed all aspects of the study, including but not limited to the purpose, procedures, risks, benefits, and the methods of data collection and processing. (5) Participants were informed about how their personal information would be kept confidential and how the data would be securely stored and processed. (6) It was clearly explained to participants how their data would be used, including whether it would be shared with third parties and under what conditions. (7) Participants were informed of their right to receive updated information during the research process if there were any significant changes to the purpose, procedures, or risks of the study. (8) Communication with participants was maintained throughout the research process to ensure they continued to understand the progress and had the opportunity to ask questions or withdraw.</p>
      <p>The research protocol of this study, including the methods of sleep data collection, has been reviewed and approved by the Biomedical Research Ethics Committee of the Affiliated Hospital of Binzhou Medical University. Throughout the research process, this study has continuously complied with the regulations and requirements set forth by the Ethics Review Committee, including the ethical principles outlined in the Declaration of Helsinki.</p>
    </ack>
    <sec sec-type="COI-statement" id="s0006">
      <title>Disclosure</title>
      <p>The authors report no conflicts of interest in this work.</p>
    </sec>
    <ref-list>
      <title>References</title>
      <ref id="cit0001">
        <label>1.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Mellinger Glen</surname>
<given-names>D</given-names></string-name>. <article-title>Insomnia and its treatment</article-title>. <source><italic toggle="yes">Arch Gen Psychiatry</italic></source>. <year>1985</year>;<volume>42</volume>(<issue>3</issue>):<fpage>225</fpage>. doi:<pub-id pub-id-type="doi">10.1001/archpsyc.1985.01790260019002</pub-id><pub-id pub-id-type="pmid">2858188</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0002">
        <label>2.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Charbonnier</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Zoubek</surname>
<given-names>L</given-names></string-name>, <string-name><surname>Lesecq</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Chapotot</surname>
<given-names>F</given-names></string-name>. <article-title>Self-evaluated automatic classifier as a decision-support tool for sleep/wake staging</article-title>. <source><italic toggle="yes">Comput Biol Med</italic></source>. <year>2011</year>;<volume>41</volume>(<issue>6</issue>):<fpage>380</fpage>–<lpage>389</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.compbiomed.2011.04.001</pub-id><pub-id pub-id-type="pmid">21497802</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0003">
        <label>3.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Geng</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Zhao</surname>
<given-names>J</given-names></string-name>, <string-name><surname>Dong</surname>
<given-names>J</given-names></string-name>, <string-name><surname>Jiang</surname>
<given-names>X</given-names></string-name>, <string-name><surname>Gómez</surname>
<given-names>C</given-names></string-name>, <string-name><surname>Schwarzacher</surname>
<given-names>SP</given-names></string-name>. <article-title>Comparison of support vector machines based on particle swarm optimization and genetic algorithm in sleep staging</article-title>. <source><italic toggle="yes">Technol Health Care</italic></source>. <year>2019</year>;<volume>27</volume>(<issue>S1</issue>):<fpage>143</fpage>–<lpage>151</lpage>. doi:<pub-id pub-id-type="doi">10.3233/THC-199014</pub-id><pub-id pub-id-type="pmid">31045534</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0004">
        <label>4.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Walthert</surname>
<given-names>L</given-names></string-name>, <string-name><surname>Bauerfeind</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Kumar</surname>
<given-names>S</given-names></string-name>. <article-title>An automated random forest algorithm for sleep staging using advanced cardiorespiratory and movement features</article-title>. <source><italic toggle="yes">Sleep Med</italic></source>. <year>2019</year>;<volume>64</volume>(<issue>S1</issue>):<fpage>S206</fpage>–<lpage>S206</lpage>.</mixed-citation>
      </ref>
      <ref id="cit0005">
        <label>5.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Huang</surname>
<given-names>W</given-names></string-name>, <string-name><surname>Guo</surname>
<given-names>B</given-names></string-name>, <string-name><surname>Shen</surname>
<given-names>Y</given-names></string-name>, et al. <article-title>Sleep staging algorithm based on multichannel data adding and multifeature screening</article-title>. <source><italic toggle="yes">Comput Methods Programs Biomed</italic></source>. <year>2020</year>;<volume>187</volume>:<fpage>105253</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cmpb.2019.105253</pub-id><pub-id pub-id-type="pmid">31812884</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0006">
        <label>6.</label>
        <mixed-citation publication-type="confproc"><string-name><surname>Hassan</surname>
<given-names>AR</given-names></string-name>, <string-name><surname>Bhuiyan</surname>
<given-names>MIH</given-names></string-name>. <article-title>Automatic sleep stage classification</article-title>. <conf-name>Paper presented at: International Conference on Electrical Information &amp; Communication Technology</conf-name>; <year>2016</year>.</mixed-citation>
      </ref>
      <ref id="cit0007">
        <label>7.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Jia-Yi</surname>
<given-names>GE</given-names></string-name>, <string-name><surname>Peng</surname>
<given-names>Z</given-names></string-name>, <string-name><surname>Xin</surname>
<given-names>Z</given-names></string-name>, <string-name><surname>Hai-Ying</surname>
<given-names>L</given-names></string-name>. <article-title>Multiscale entropy analysis of EEG signal</article-title>. <source><italic toggle="yes">Com Eng App</italic></source>. <year>2009</year>;<volume>45</volume>(<issue>10</issue>):<fpage>13</fpage>–<lpage>15</lpage>.</mixed-citation>
      </ref>
      <ref id="cit0008">
        <label>8.</label>
        <mixed-citation publication-type="newspaper"><string-name><surname>Larsen</surname>
<given-names>L</given-names></string-name>, <string-name><surname>Walter</surname>
<given-names>D</given-names></string-name>. <article-title>Classification of sleep stages by EEG spectra</article-title>; <year>1969</year>.</mixed-citation>
      </ref>
      <ref id="cit0009">
        <label>9.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Vincent</surname>
<given-names>LC-F</given-names></string-name>, <string-name><surname>Jaeseung</surname>
<given-names>J</given-names></string-name>. <article-title>Quantification of brain macrostates using dynamical nonstationarity of physiological time series</article-title>. <source><italic toggle="yes">IEEE Trans Bio-Med Eng</italic></source>. <year>2011</year>;<volume>58</volume>(<issue>4</issue>):<fpage>1084</fpage>–<lpage>1093</lpage>. doi:<pub-id pub-id-type="doi">10.1109/TBME.2009.2034840</pub-id></mixed-citation>
      </ref>
      <ref id="cit0010">
        <label>10.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Fraiwan</surname>
<given-names>L</given-names></string-name>, <string-name><surname>Lweesy</surname>
<given-names>K</given-names></string-name>, <string-name><surname>Khasawneh</surname>
<given-names>N</given-names></string-name>, <string-name><surname>Wenz</surname>
<given-names>H</given-names></string-name>, <string-name><surname>Dickhaus</surname>
<given-names>H</given-names></string-name>. <article-title>Automated sleep stage identification system based on time–frequency analysis of a single EEG channel and random forest classifier</article-title>. <source><italic toggle="yes">Comput Methods Programs Biomed.</italic></source>
<year>2012</year>;<volume>108</volume>(<issue>1</issue>):<fpage>10</fpage>–<lpage>19</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cmpb.2011.11.005</pub-id><pub-id pub-id-type="pmid">22178068</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0011">
        <label>11.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Weiss</surname>
<given-names>B</given-names></string-name>, <string-name><surname>Clemens</surname>
<given-names>Z</given-names></string-name>, <string-name><surname>Bódizs</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Halász</surname>
<given-names>P</given-names></string-name>. <article-title>Comparison of fractal and power spectral EEG features: effects of topography and sleep stages</article-title>. <source><italic toggle="yes">Brain Res Bull</italic></source>. <year>2010</year>;<volume>84</volume>(<issue>6</issue>):<fpage>359</fpage>–<lpage>375</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.brainresbull.2010.12.005</pub-id><pub-id pub-id-type="pmid">21147200</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0012">
        <label>12.</label>
        <mixed-citation publication-type="journal"><string-name><surname>K</surname>
<given-names>D-K</given-names></string-name>, <string-name><surname>K</surname>
<given-names>D</given-names></string-name>, <string-name><surname>L</surname>
<given-names>J-G</given-names></string-name>, <string-name><surname>W</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>J</surname>
<given-names>J</given-names></string-name>. <article-title>Deep learning application to clinical decision support system in sleep stage classification</article-title>. <source><italic toggle="yes">Sleep Med</italic></source>. <year>2022</year>;<volume>100</volume>(<issue>S1</issue>):<fpage>136</fpage>.</mixed-citation>
      </ref>
      <ref id="cit0013">
        <label>13.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Fernando</surname>
<given-names>-V-V</given-names></string-name>, <string-name><surname>G-tg</surname>
<given-names>C</given-names></string-name>, <string-name><surname>Eva</surname>
<given-names>C</given-names></string-name>, et al. <article-title>An explainable deep-learning model to stage sleep states in children and propose novel EEG-related patterns in sleep apnea</article-title>. <source><italic toggle="yes">Comput Biol Med</italic></source>. <year>2023</year>;<volume>165</volume>:<fpage>107419</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.compbiomed.2023.107419</pub-id><pub-id pub-id-type="pmid">37703716</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0014">
        <label>14.</label>
        <mixed-citation publication-type="confproc"><string-name><surname>R</surname>
<given-names>M</given-names></string-name>, <string-name><surname>H</surname>
<given-names>R</given-names></string-name>, <string-name><surname>K</surname>
<given-names>H</given-names></string-name>, et al. <article-title>Generalizable deep learning-based sleep staging approach for ambulatory textile electrode headband recordings</article-title>. <conf-name>IEEE journal of biomedical and health informatics</conf-name>; <year>2023</year>.</mixed-citation>
      </ref>
      <ref id="cit0015">
        <label>15.</label>
        <mixed-citation publication-type="confproc"><string-name><surname>Wei</surname>
<given-names>L</given-names></string-name>, <string-name><surname>Lin</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname>
<given-names>J</given-names></string-name>, <string-name><surname>Ma</surname>
<given-names>Y</given-names></string-name>. <article-title>Time-frequency convolutional neural network for automatic sleep stage classification based on single-channel EEG</article-title>. In: <conf-name>2017 IEEE 29th International Conference on Tools with Artificial Intelligence</conf-name>. <publisher-name>IEEE</publisher-name>; <year>2017</year>.</mixed-citation>
      </ref>
      <ref id="cit0016">
        <label>16.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Emin</surname>
<given-names>TM</given-names></string-name>, <string-name><surname>Necmettin</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Mehmet</surname>
<given-names>A</given-names></string-name>. <article-title>Estimation of sleep stages by an artificial neural network employing EEG, EMG and EOG</article-title>. <source><italic toggle="yes">J Med Syst</italic></source>. <year>2010</year>;<volume>34</volume>(<issue>4</issue>):<fpage>717</fpage>–<lpage>725</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s10916-009-9286-5</pub-id><pub-id pub-id-type="pmid">20703927</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0017">
        <label>17.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Sors</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Bonnet</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Mirek</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Vercueil</surname>
<given-names>L</given-names></string-name>, <string-name><surname>Payen</surname>
<given-names>J-F</given-names></string-name>. <article-title>A convolutional neural network for sleep stage scoring from raw single-channel EEG</article-title>. <source><italic toggle="yes">Biomed Signal Process Control</italic></source>. <year>2018</year>;<volume>42</volume>:<fpage>107</fpage>–<lpage>114</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.bspc.2017.12.001</pub-id></mixed-citation>
      </ref>
      <ref id="cit0018">
        <label>18.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Hsu</surname>
<given-names>Y-L</given-names></string-name>, <string-name><surname>Yang</surname>
<given-names>Y-TC</given-names></string-name>, <string-name><surname>Wang</surname>
<given-names>J-S</given-names></string-name>, <string-name><surname>Hsu</surname>
<given-names>C-Y</given-names></string-name>. <article-title>Automatic sleep stage recurrent neural classifier using energy features of EEG signals</article-title>. <source><italic toggle="yes">Neurocomputing</italic></source>. <year>2013</year>;<volume>104</volume>:<fpage>105</fpage>–<lpage>114</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neucom.2012.11.003</pub-id></mixed-citation>
      </ref>
      <ref id="cit0019">
        <label>19.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Akara</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Hao</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Chao</surname>
<given-names>W</given-names></string-name>, <string-name><surname>Yike</surname>
<given-names>G</given-names></string-name>. <article-title>DeepSleepNet: a model for automatic sleep stage scoring based on raw single-channel EEG</article-title>. <source><italic toggle="yes">IEEE Trans Neural Syst Rehabilit Eng</italic></source>. <year>2017</year>;<volume>25</volume>(<issue>11</issue>):<fpage>1998</fpage>–<lpage>2008</lpage>. doi:<pub-id pub-id-type="doi">10.1109/TNSRE.2017.2721116</pub-id></mixed-citation>
      </ref>
      <ref id="cit0020">
        <label>20.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Jaemin</surname>
<given-names>J</given-names></string-name>, <string-name><surname>Wonhyuck</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>JeongGun</surname>
<given-names>L</given-names></string-name>, et al. <article-title>Standardized image-based polysomnography database and deep learning algorithm for sleep stage classification</article-title>. <source><italic toggle="yes">Sleep</italic></source>. <year>2023</year>;<volume>46</volume>(<issue>12</issue>):<fpage>zsad242</fpage>.<pub-id pub-id-type="pmid">37703391</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0021">
        <label>21.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Dongrae</surname>
<given-names>C</given-names></string-name>, <string-name><surname>Boreom</surname>
<given-names>L</given-names></string-name>. <article-title>Automatic sleep-stage classification based on residual unit and attention networks using directed transfer function of electroencephalogram signals</article-title>. <source><italic toggle="yes">Biomed Sig Process Control</italic></source>. <year>2024</year>;<volume>88</volume>(<issue>PB</issue>):<fpage>105679</fpage>.</mixed-citation>
      </ref>
      <ref id="cit0022">
        <label>22.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Helli</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Fortune</surname>
<given-names>RD</given-names></string-name>. <article-title>The neuronal transition probability (NTP) model for the dynamic progression of non-REM sleep EEG: the role of the suprachiasmatic nucleus</article-title>. <source><italic toggle="yes">PLoS One</italic></source>. <year>2011</year>;<volume>6</volume>(<issue>8</issue>):<fpage>e23593</fpage>.<pub-id pub-id-type="pmid">21886801</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0023">
        <label>23.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Uchida</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Maloney</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Feinberg</surname>
<given-names>I</given-names></string-name>. <article-title>Beta (20–28 Hz) and delta (0.3–3 Hz) EEGs oscillate reciprocally across NREM and REM sleep</article-title>. <source><italic toggle="yes">Sleep</italic></source>. <year>1992</year>;<volume>15</volume>(<issue>4</issue>):<fpage>352</fpage>–<lpage>358</lpage>. doi:<pub-id pub-id-type="doi">10.1093/sleep/15.4.352</pub-id><pub-id pub-id-type="pmid">1519011</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0024">
        <label>24.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Uchida</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Maloney</surname>
<given-names>T</given-names></string-name>, <string-name><surname>March</surname>
<given-names>JD</given-names></string-name>, <string-name><surname>Azari</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Feinberg</surname>
<given-names>I</given-names></string-name>. <article-title>Sigma (12–15 Hz) and delta (0.3–3 Hz) EEG oscillate reciprocally within NREM sleep</article-title>. <source><italic toggle="yes">Brain Res Bull</italic></source>. <year>1991</year>;<volume>27</volume>(<issue>1</issue>):<fpage>93</fpage>–<lpage>96</lpage>. doi:<pub-id pub-id-type="doi">10.1016/0361-9230(91)90286-S</pub-id><pub-id pub-id-type="pmid">1933440</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0025">
        <label>25.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Pardey</surname>
<given-names>J</given-names></string-name>, <string-name><surname>Roberts</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Tarassenko</surname>
<given-names>L</given-names></string-name>, <string-name><surname>Stradling</surname>
<given-names>J</given-names></string-name>. <article-title>A new approach to the analysis of the human sleep/wakefulness continuum</article-title>. <source><italic toggle="yes">J Sleep Res</italic></source>. <year>2010</year>;<volume>5</volume>(<issue>4</issue>):<fpage>201</fpage>–<lpage>210</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1365-2869.1996.00201.x</pub-id></mixed-citation>
      </ref>
      <ref id="cit0026">
        <label>26.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Asyali</surname>
<given-names>MH</given-names></string-name>, <string-name><surname>Berry</surname>
<given-names>RB</given-names></string-name>, <string-name><surname>Khoo</surname>
<given-names>MCK</given-names></string-name>, <string-name><surname>Altinok</surname>
<given-names>A</given-names></string-name>. <article-title>Determining a continuous marker for sleep depth</article-title>. <source><italic toggle="yes">Comput Biol Med</italic></source>. <year>2007</year>;<volume>37</volume>(<issue>11</issue>):<fpage>1600</fpage>–<lpage>1609</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.compbiomed.2007.03.001</pub-id><pub-id pub-id-type="pmid">17434160</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0027">
        <label>27.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Magdy</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Michele</surname>
<given-names>O</given-names></string-name>, <string-name><surname>Marc</surname>
<given-names>S</given-names></string-name>, et al. <article-title>Odds ratio product of sleep EEG as a continuous measure of sleep state</article-title>. <source><italic toggle="yes">Sleep</italic></source>. <year>2015</year>;<volume>38</volume>(<issue>4</issue>):<fpage>641</fpage>–<lpage>654</lpage>. doi:<pub-id pub-id-type="doi">10.5665/sleep.4588</pub-id><pub-id pub-id-type="pmid">25348125</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0028">
        <label>28.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Magdy</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Ali</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Michelle</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Md</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Susan</surname>
<given-names>R</given-names></string-name>. <article-title>Characteristics and reproducibility of novel sleep EEG biomarkers and their variation with sleep apnea and insomnia in a large community-based cohort</article-title>. <source><italic toggle="yes">Sleep</italic></source>. <year>2021</year>;<volume>44</volume>(<issue>10</issue>):<fpage>zsab145</fpage>.<pub-id pub-id-type="pmid">34156473</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0029">
        <label>29.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Magdy</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Bethany</surname>
<given-names>G</given-names></string-name>, <string-name><surname>Pack</surname>
<given-names>AI</given-names></string-name>, <string-name><surname>Kuna</surname>
<given-names>ST</given-names></string-name>, <string-name><surname>Cecilia</surname>
<given-names>C</given-names></string-name>, <string-name><surname>Susan</surname>
<given-names>R</given-names></string-name>. <article-title>Sleep architecture based on sleep depth and propensity: patterns in different demographics and sleep disorders and association with health outcomes</article-title>. <source><italic toggle="yes">Sleep</italic></source>. <year>2022</year>;<volume>45</volume>(<issue>6</issue>):<fpage>zsac059</fpage>.<pub-id pub-id-type="pmid">35272350</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0030">
        <label>30.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Magdy</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Bethany</surname>
<given-names>G</given-names></string-name>, <string-name><surname>Eleni</surname>
<given-names>G</given-names></string-name>, et al. <article-title>Contribution of obstructive sleep apnea to disrupted sleep in a large clinical cohort of patients with suspected OSA</article-title>. <source><italic toggle="yes">Sleep</italic></source>. <year>2023</year>;<volume>46</volume>(<issue>7</issue>):<fpage>zsac321</fpage>.<pub-id pub-id-type="pmid">36591638</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0031">
        <label>31.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Bethany</surname>
<given-names>G</given-names></string-name>, <string-name><surname>Ks</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Allan</surname>
<given-names>P</given-names></string-name>, et al. <article-title>An approach for determining the reliability of manual and digital scoring of sleep stages</article-title>. <source><italic toggle="yes">Sleep</italic></source>. <year>2023</year>;<volume>46</volume>(<issue>11</issue>):<fpage>zsad248</fpage>.<pub-id pub-id-type="pmid">37712522</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0032">
        <label>32.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Sultan</surname>
<given-names>Q</given-names></string-name>, <string-name><surname>Hani</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Faris</surname>
<given-names>A</given-names></string-name>, et al. <article-title>The prevalence of rapid eye movement-related obstructive sleep apnea in a sample of Saudi population</article-title>. <source><italic toggle="yes">Ann Thorac Med</italic></source>. <year>2023</year>;<volume>18</volume>(<issue>2</issue>):<fpage>90</fpage>–<lpage>97</lpage>. doi:<pub-id pub-id-type="doi">10.4103/atm.atm_388_22</pub-id><pub-id pub-id-type="pmid">37323370</pub-id>
</mixed-citation>
      </ref>
      <ref id="cit0033">
        <label>33.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Anna</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Cs</surname>
<given-names>L</given-names></string-name>, <string-name><surname>Fan</surname>
<given-names>H</given-names></string-name>, et al. <article-title>Association of a novel EEG metric of sleep depth/intensity with attention-deficit/hyperactivity, learning and internalizing disorders and their pharmacotherapy in adolescence</article-title>. <source><italic toggle="yes">Sleep</italic></source>. <year>2021</year>;<volume>45</volume>(<issue>3</issue>):<fpage>zsab287</fpage>.</mixed-citation>
      </ref>
      <ref id="cit0034">
        <label>34.</label>
        <mixed-citation publication-type="journal"><string-name><surname>Julio</surname>
<given-names>FM</given-names></string-name>, <string-name><surname>Anna</surname>
<given-names>R</given-names></string-name>, <string-name><surname>Fan</surname>
<given-names>H</given-names></string-name>, et al. <article-title>0254 association of slow wave activity and odds ratio product with internalizing and externalizing problems in children and adolescents</article-title>. <source><italic toggle="yes">Sleep</italic></source>. <year>2022</year>(<issue>Supplement_1</issue>):<fpage>A114</fpage>.</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
</pmc-articleset>
